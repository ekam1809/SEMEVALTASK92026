{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cbbc9cb",
   "metadata": {},
   "source": [
    "## Setup, config, paths, model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 10:50:07.454455: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-08 10:50:19.303035: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765219820.347298 4030100 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765219821.052863 4030100 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1765219823.883024 4030100 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765219823.883061 4030100 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765219823.883063 4030100 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765219823.883065 4030100 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-12-08 10:50:24.472403: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.0\n",
      "Transformers: 4.57.1\n",
      "Using GPU: NVIDIA H100 80GB HBM3 MIG 2g.20gb\n",
      "LANG=eng\n",
      "T2_LABELS: ['gender/sexual', 'political', 'religious', 'racial/ethnic', 'other']\n",
      "T3_LABELS: ['vilification', 'extreme_language', 'stereotype', 'invalidation', 'lack_of_empathy', 'dehumanization']\n",
      "\n",
      "Loading Qwen2.5-7B-Instruct... (this may take a moment)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.01s/it]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen pipeline ready on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# # method3 — Qwen2.5-7B LLM predictions (few-shot, all subtasks)\n",
    "#\n",
    "# - Uses Qwen/Qwen2.5-7B-Instruct as a multilingual **few-shot classifier** (no fine-tuning).\n",
    "# - Works directly on the original language (no translation).\n",
    "# - For each subtask, builds a **label-balanced few-shot context** from TRAIN examples:\n",
    "#   - Subtask 1: binary polarization.\n",
    "#   - Subtask 2: multi-label (5 hate types).\n",
    "#   - Subtask 3: multi-label (6 manifestations).\n",
    "# - Outputs per-example predictions for TRAIN and DEV for all 3 subtasks.\n",
    "# - Caches go into: `cache/qwen5shots/<LANG>/`\n",
    "# - Optional Qwen-only submissions go into: `submissions/qwen5shots/subtask_X/`\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "import transformers\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"Transformers:\", transformers.__version__)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Device selection: GPU strongly recommended for Qwen\n",
    "# ------------------------------------------------------------\n",
    "RUN_DEVICE = \"gpu\"  # \"gpu\" or \"cpu\"\n",
    "\n",
    "if RUN_DEVICE.lower() == \"gpu\" and torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.set_num_threads(max(1, os.cpu_count() // 2))\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Reproducibility\n",
    "# ------------------------------------------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if DEVICE.type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# High-level config\n",
    "# ------------------------------------------------------------\n",
    "# Change LANG when you switch language (eng, ben, hin, etc.)\n",
    "LANG = \"eng\"\n",
    "\n",
    "BASE = \"../dev_phase\"  # root of organizer data\n",
    "\n",
    "# Qwen model:\n",
    "QWEN_MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "# Paths for data (TRAIN has labels, DEV is unlabeled for Codabench)\n",
    "lang_fname = LANG\n",
    "\n",
    "T1_TRAIN = f\"{BASE}/subtask1/train/{lang_fname}.csv\"\n",
    "T1_DEV   = f\"{BASE}/subtask1/dev/{lang_fname}.csv\"\n",
    "\n",
    "T2_TRAIN = f\"{BASE}/subtask2/train/{lang_fname}.csv\"\n",
    "T2_DEV   = f\"{BASE}/subtask2/dev/{lang_fname}.csv\"\n",
    "\n",
    "T3_TRAIN = f\"{BASE}/subtask3/train/{lang_fname}.csv\"\n",
    "T3_DEV   = f\"{BASE}/subtask3/dev/{lang_fname}.csv\"\n",
    "\n",
    "# Caches + outputs for Qwen few-shot\n",
    "CACHE_ROOT = Path(\"cache\") / \"qwen5shots\" / LANG\n",
    "OUT_ROOT   = Path(\"outputs\") / \"qwen5shots\" / LANG\n",
    "SUB_ROOT   = Path(\"submissions\") / \"qwen5shots\"\n",
    "\n",
    "for d in [CACHE_ROOT, OUT_ROOT, SUB_ROOT]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "(SUB_ROOT / \"subtask_1\").mkdir(parents=True, exist_ok=True)\n",
    "(SUB_ROOT / \"subtask_2\").mkdir(parents=True, exist_ok=True)\n",
    "(SUB_ROOT / \"subtask_3\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Label order for multi-label tasks (same as other methods)\n",
    "T2_LABELS = [\"gender/sexual\", \"political\", \"religious\", \"racial/ethnic\", \"other\"]\n",
    "T3_LABELS = [\n",
    "    \"vilification\",\n",
    "    \"extreme_language\",\n",
    "    \"stereotype\",\n",
    "    \"invalidation\",\n",
    "    \"lack_of_empathy\",\n",
    "    \"dehumanization\",\n",
    "]\n",
    "\n",
    "print(f\"LANG={LANG}\")\n",
    "print(\"T2_LABELS:\", T2_LABELS)\n",
    "print(\"T3_LABELS:\", T3_LABELS)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load Qwen2.5-7B-Instruct via pipeline\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nLoading Qwen2.5-7B-Instruct... (this may take a moment)\")\n",
    "\n",
    "dtype = torch.bfloat16 if DEVICE.type == \"cuda\" else torch.float32\n",
    "\n",
    "llm_tokenizer = AutoTokenizer.from_pretrained(QWEN_MODEL_NAME, use_fast=True)\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "    QWEN_MODEL_NAME,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=\"auto\" if DEVICE.type == \"cuda\" else None,\n",
    ")\n",
    "llm_model.eval()\n",
    "\n",
    "llm_pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=llm_model,\n",
    "    tokenizer=llm_tokenizer,\n",
    "    # pipeline will handle device via model.device\n",
    ")\n",
    "\n",
    "print(\"Qwen pipeline ready on device:\", llm_model.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857696c6",
   "metadata": {},
   "source": [
    "## Helpers: metrics, few-shot builders, prompts, parsers, batch runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d12f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Helpers: metrics, few-shot contexts, prompts, parsers, batch inference\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Few-shot context builders (label-balanced)\n",
    "# ------------------------------------------------------------\n",
    "def build_fewshot_context_t1(df: pd.DataFrame, lang: str,\n",
    "                             n_pos: int = 3, n_neg: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Build a few-shot context for Subtask 1:\n",
    "    - Aim for n_pos positive examples (polarization=1)\n",
    "    - Aim for n_neg negative examples (polarization=0)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"polarization\"] = df[\"polarization\"].astype(int)\n",
    "\n",
    "    df_pos = df[df[\"polarization\"] == 1]\n",
    "    df_neg = df[df[\"polarization\"] == 0]\n",
    "\n",
    "    rng = np.random.RandomState(42)\n",
    "    examples = []\n",
    "\n",
    "    if len(df_pos) > 0:\n",
    "        n_pos = min(n_pos, len(df_pos))\n",
    "        examples.append(df_pos.sample(n=n_pos, random_state=42))\n",
    "    if len(df_neg) > 0:\n",
    "        n_neg = min(n_neg, len(df_neg))\n",
    "        examples.append(df_neg.sample(n=n_neg, random_state=43))\n",
    "\n",
    "    if examples:\n",
    "        ex_df = pd.concat(examples, ignore_index=True)\n",
    "    else:\n",
    "        # fallback: just sample up to 6 rows\n",
    "        ex_df = df.sample(n=min(6, len(df)), random_state=42)\n",
    "\n",
    "    ex_df = ex_df.reset_index(drop=True)\n",
    "\n",
    "    lines = []\n",
    "    for i, row in ex_df.iterrows():\n",
    "        label = int(row[\"polarization\"])\n",
    "        txt = str(row[\"text\"]).strip().replace(\"\\n\", \" \")\n",
    "        lines.append(\n",
    "            f\"Example {i+1}:\\n\"\n",
    "            f\"Post: {txt}\\n\"\n",
    "            f\"Label (0=non-hate, 1=hate/polarizing): {label}\\n\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(lines).strip()\n",
    "\n",
    "\n",
    "def build_fewshot_context_t2(df: pd.DataFrame, lang: str,\n",
    "                             max_examples_per_label: int = 1,\n",
    "                             n_negatives: int = 2) -> str:\n",
    "    \"\"\"\n",
    "    Build a label-balanced few-shot context for Subtask 2 (5 labels).\n",
    "    Goal:\n",
    "      - For each label in T2_LABELS, pick up to `max_examples_per_label`\n",
    "        examples where that label == 1.\n",
    "        Prefer \"focused\" examples where only that label is 1.\n",
    "      - Add up to `n_negatives` all-zero examples.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for lab in T2_LABELS:\n",
    "        df[lab] = df[lab].astype(int)\n",
    "\n",
    "    rng = np.random.RandomState(42)\n",
    "    used_indices = set()\n",
    "    examples = []\n",
    "\n",
    "    # Label-focused positives\n",
    "    for lab in T2_LABELS:\n",
    "        df_lab_pos = df[df[lab] == 1]\n",
    "        if df_lab_pos.empty:\n",
    "            continue\n",
    "\n",
    "        # Prefer rows where this label is the ONLY 1\n",
    "        df_lab_pure = df_lab_pos[df_lab_pos[T2_LABELS].sum(axis=1) == 1]\n",
    "\n",
    "        if not df_lab_pure.empty:\n",
    "            row = df_lab_pure.sample(n=1, random_state=42).iloc[0]\n",
    "        else:\n",
    "            # fallback: any row with lab==1\n",
    "            row = df_lab_pos.sample(n=1, random_state=42).iloc[0]\n",
    "\n",
    "        idx = row.name\n",
    "        if idx in used_indices:\n",
    "            continue\n",
    "        used_indices.add(idx)\n",
    "        examples.append(row)\n",
    "\n",
    "    # Add negative examples (all labels = 0)\n",
    "    if n_negatives > 0:\n",
    "        df_neg = df[df[T2_LABELS].sum(axis=1) == 0]\n",
    "        if not df_neg.empty:\n",
    "            n_neg = min(n_negatives, len(df_neg))\n",
    "            df_neg_sample = df_neg.sample(n=n_neg, random_state=123)\n",
    "            for _, row in df_neg_sample.iterrows():\n",
    "                idx = row.name\n",
    "                if idx in used_indices:\n",
    "                    continue\n",
    "                used_indices.add(idx)\n",
    "                examples.append(row)\n",
    "\n",
    "    # If for some reason we still have no examples, fallback to random sampling\n",
    "    if not examples:\n",
    "        ex_df = df.sample(n=min(5, len(df)), random_state=42)\n",
    "    else:\n",
    "        ex_df = pd.DataFrame(examples)\n",
    "\n",
    "    ex_df = ex_df.reset_index(drop=True)\n",
    "\n",
    "    lines = []\n",
    "    for i, row in ex_df.iterrows():\n",
    "        txt = str(row[\"text\"]).strip().replace(\"\\n\", \" \")\n",
    "        vec = [int(row[lab]) for lab in T2_LABELS]\n",
    "        vec_str = \" \".join(str(v) for v in vec)\n",
    "        lines.append(\n",
    "            f\"Example {i+1}:\\n\"\n",
    "            f\"Post: {txt}\\n\"\n",
    "            f\"Labels (gender/sexual, political, religious, \"\n",
    "            f\"racial/ethnic, other): {vec_str}\\n\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(lines).strip()\n",
    "\n",
    "\n",
    "def build_fewshot_context_t3(df: pd.DataFrame, lang: str,\n",
    "                             max_examples_per_label: int = 1,\n",
    "                             n_negatives: int = 2) -> str:\n",
    "    \"\"\"\n",
    "    Build a label-balanced few-shot context for Subtask 3 (6 labels).\n",
    "    Goal:\n",
    "      - For each label in T3_LABELS, pick up to `max_examples_per_label`\n",
    "        examples where that label == 1.\n",
    "        Prefer \"focused\" examples where only that label is 1.\n",
    "      - Add up to `n_negatives` all-zero examples.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for lab in T3_LABELS:\n",
    "        df[lab] = df[lab].astype(int)\n",
    "\n",
    "    rng = np.random.RandomState(42)\n",
    "    used_indices = set()\n",
    "    examples = []\n",
    "\n",
    "    # Label-focused positives\n",
    "    for lab in T3_LABELS:\n",
    "        df_lab_pos = df[df[lab] == 1]\n",
    "        if df_lab_pos.empty:\n",
    "            continue\n",
    "\n",
    "        # Prefer rows where this label is the ONLY 1\n",
    "        df_lab_pure = df_lab_pos[df_lab_pos[T3_LABELS].sum(axis=1) == 1]\n",
    "\n",
    "        if not df_lab_pure.empty:\n",
    "            row = df_lab_pure.sample(n=1, random_state=42).iloc[0]\n",
    "        else:\n",
    "            # fallback: any row with lab==1\n",
    "            row = df_lab_pos.sample(n=1, random_state=42).iloc[0]\n",
    "\n",
    "        idx = row.name\n",
    "        if idx in used_indices:\n",
    "            continue\n",
    "        used_indices.add(idx)\n",
    "        examples.append(row)\n",
    "\n",
    "    # Add negative examples (all labels = 0)\n",
    "    if n_negatives > 0:\n",
    "        df_neg = df[df[T3_LABELS].sum(axis=1) == 0]\n",
    "        if not df_neg.empty:\n",
    "            n_neg = min(n_negatives, len(df_neg))\n",
    "            df_neg_sample = df_neg.sample(n=n_neg, random_state=123)\n",
    "            for _, row in df_neg_sample.iterrows():\n",
    "                idx = row.name\n",
    "                if idx in used_indices:\n",
    "                    continue\n",
    "                used_indices.add(idx)\n",
    "                examples.append(row)\n",
    "\n",
    "    if not examples:\n",
    "        ex_df = df.sample(n=min(6, len(df)), random_state=42)\n",
    "    else:\n",
    "        ex_df = pd.DataFrame(examples)\n",
    "\n",
    "    ex_df = ex_df.reset_index(drop=True)\n",
    "\n",
    "    lines = []\n",
    "    for i, row in ex_df.iterrows():\n",
    "        txt = str(row[\"text\"]).strip().replace(\"\\n\", \" \")\n",
    "        vec = [int(row[lab]) for lab in T3_LABELS]\n",
    "        vec_str = \" \".join(str(v) for v in vec)\n",
    "        lines.append(\n",
    "            f\"Example {i+1}:\\n\"\n",
    "            f\"Post: {txt}\\n\"\n",
    "            f\"Labels (vilification, extreme_language, stereotype, \"\n",
    "            f\"invalidation, lack_of_empathy, dehumanization): {vec_str}\\n\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(lines).strip()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Few-shot prompt builders\n",
    "# ------------------------------------------------------------\n",
    "def build_prompt_t1(text: str, lang: str, fewshot_ctx: str) -> str:\n",
    "    \"\"\"\n",
    "    Subtask 1: binary polarization, few-shot prompt.\n",
    "    Output format: single digit 0 or 1.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "You are an expert annotator for online hate and polarization detection.\n",
    "\n",
    "Language code of the text: {lang}\n",
    "\n",
    "Task:\n",
    "Given a social media post, decide whether it contains hateful, abusive, or strongly polarizing content.\n",
    "\n",
    "Classes:\n",
    "0 = NON_HATE / NOT_POLARIZING (neutral, non-hateful content)\n",
    "1 = HATE / POLARIZING (hateful, abusive, or strongly polarizing content)\n",
    "\n",
    "Below are some EXAMPLES with their correct labels:\n",
    "\n",
    "{fewshot_ctx}\n",
    "\n",
    "Now classify THIS NEW post.\n",
    "\n",
    "Instructions:\n",
    "- Read the post carefully.\n",
    "- Decide which class is more appropriate.\n",
    "- Answer with ONLY ONE DIGIT: 0 or 1.\n",
    "- Do not include any additional words or explanation.\n",
    "\n",
    "New post:\n",
    "{text}\n",
    "\n",
    "Answer (0 or 1 only):\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def build_prompt_t2(text: str, lang: str, fewshot_ctx: str) -> str:\n",
    "    \"\"\"\n",
    "    Subtask 2: multi-label 5-way, few-shot prompt.\n",
    "    Output format: 5 digits (0/1) in fixed order.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "You are an expert annotator for hate type classification in online text.\n",
    "\n",
    "Language code of the text: {lang}\n",
    "\n",
    "Task:\n",
    "Given a social media post, decide which hate types are present.\n",
    "There can be multiple hate types at the same time, or none.\n",
    "\n",
    "Label order (5 labels):\n",
    "1) gender/sexual\n",
    "2) political\n",
    "3) religious\n",
    "4) racial/ethnic\n",
    "5) other\n",
    "\n",
    "Below are some EXAMPLES with their correct 5-label vectors:\n",
    "(Each vector is: gender/sexual, political, religious, racial/ethnic, other)\n",
    "\n",
    "{fewshot_ctx}\n",
    "\n",
    "Now classify THIS NEW post.\n",
    "\n",
    "Output format:\n",
    "Return EXACTLY 5 digits, each 0 or 1, separated by spaces.\n",
    "- 1 means the hate type is present.\n",
    "- 0 means the hate type is not present.\n",
    "Example output: \"0 1 0 0 1\"\n",
    "\n",
    "Important:\n",
    "- Return ONLY the 5 digits, nothing else.\n",
    "- Do NOT write label names or explanations.\n",
    "\n",
    "New post:\n",
    "{text}\n",
    "\n",
    "Answer (5 digits for the 5 labels, in order):\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def build_prompt_t3(text: str, lang: str, fewshot_ctx: str) -> str:\n",
    "    \"\"\"\n",
    "    Subtask 3: multi-label 6-way, few-shot prompt.\n",
    "    Output format: 6 digits (0/1) in fixed order.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "You are an expert annotator for manifestations of hate in online text.\n",
    "\n",
    "Language code of the text: {lang}\n",
    "\n",
    "Task:\n",
    "Given a social media post, decide which manifestations of hate are present.\n",
    "There can be multiple manifestations at the same time, or none.\n",
    "\n",
    "Label order (6 labels):\n",
    "1) vilification\n",
    "2) extreme_language\n",
    "3) stereotype\n",
    "4) invalidation\n",
    "5) lack_of_empathy\n",
    "6) dehumanization\n",
    "\n",
    "Below are some EXAMPLES with their correct 6-label vectors:\n",
    "(Each vector is: vilification, extreme_language, stereotype,\n",
    " invalidation, lack_of_empathy, dehumanization)\n",
    "\n",
    "{fewshot_ctx}\n",
    "\n",
    "Now classify THIS NEW post.\n",
    "\n",
    "Output format:\n",
    "Return EXACTLY 6 digits, each 0 or 1, separated by spaces.\n",
    "- 1 means the manifestation is present.\n",
    "- 0 means it is not present.\n",
    "Example output: \"0 1 0 0 1 0\"\n",
    "\n",
    "Important:\n",
    "- Return ONLY the 6 digits, nothing else.\n",
    "- Do NOT write label names or explanations.\n",
    "\n",
    "New post:\n",
    "{text}\n",
    "\n",
    "Answer (6 digits for the 6 labels, in order):\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Output parsers (safer: look at last non-empty line)\n",
    "# ------------------------------------------------------------\n",
    "def parse_t1_output(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Extract first occurrence of 0 or 1 from the LAST non-empty line.\n",
    "    Default to 0 if nothing found.\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return 0\n",
    "    lines = [l.strip() for l in str(text).splitlines() if l.strip()]\n",
    "    if not lines:\n",
    "        return 0\n",
    "    last = lines[-1]\n",
    "    match = re.search(r\"[01]\", last)\n",
    "    if match:\n",
    "        return int(match.group(0))\n",
    "    return 0\n",
    "\n",
    "\n",
    "def parse_digit_vector(text: str, n_labels: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract first n_labels digits (0/1) from the LAST non-empty line.\n",
    "    Pad with zeros if fewer digits, truncate if more.\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return np.zeros(n_labels, dtype=int)\n",
    "\n",
    "    lines = [l.strip() for l in str(text).splitlines() if l.strip()]\n",
    "    if not lines:\n",
    "        return np.zeros(n_labels, dtype=int)\n",
    "    last = lines[-1]\n",
    "\n",
    "    digits = re.findall(r\"[01]\", last)\n",
    "    if len(digits) < n_labels:\n",
    "        digits = digits + [\"0\"] * (n_labels - len(digits))\n",
    "    elif len(digits) > n_labels:\n",
    "        digits = digits[:n_labels]\n",
    "\n",
    "    if not digits:\n",
    "        return np.zeros(n_labels, dtype=int)\n",
    "    return np.array([int(d) for d in digits], dtype=int)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Batch inference helper\n",
    "# ------------------------------------------------------------\n",
    "def qwen_generate_batch(\n",
    "    prompts: List[str],\n",
    "    max_new_tokens: int = 32,\n",
    "    batch_size: int = 4,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Run Qwen on a list of prompts using the chat-style pipeline.\n",
    "    Returns list of raw assistant outputs (strings).\n",
    "    \"\"\"\n",
    "    all_outputs = []\n",
    "    for start in range(0, len(prompts), batch_size):\n",
    "        batch_prompts = prompts[start:start + batch_size]\n",
    "        messages_batch = [\n",
    "            [{\"role\": \"user\", \"content\": p}] for p in batch_prompts\n",
    "        ]\n",
    "        outputs = llm_pipe(\n",
    "            messages_batch,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "        )\n",
    "        for out in outputs:\n",
    "            try:\n",
    "                msg = out[\"generated_text\"][-1][\"content\"]\n",
    "            except Exception:\n",
    "                msg = str(out)\n",
    "            all_outputs.append(msg)\n",
    "\n",
    "    assert len(all_outputs) == len(prompts)\n",
    "    return all_outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c1988b",
   "metadata": {},
   "source": [
    "## Subtask 1 (binary, few-shot Qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124613e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T1] TRAIN size: 3222\n",
      "[T1] DEV size  : 160\n",
      "\n",
      "[T1] Few-shot context (truncated):\n",
      "\n",
      "Example 1:\n",
      "Post: \"Ceasefire\" lol not even close, its just palestines unconditional surrender theyre repackaging as a ceasefire to make it look better.\n",
      "Label (0=non-hate, 1=hate/polarizing): 1\n",
      "\n",
      "Example 2:\n",
      "Post: So we going with the rigged election line for other countries now too ?\n",
      "Label (0=non-hate, 1=hate/polarizing): 1\n",
      "\n",
      "Example 3:\n",
      "Post: How would you feel about a mass deportation of my sperm?\n",
      "Label (0=non-hate, 1=hate/polarizing): 1\n",
      "\n",
      "Example 4:\n",
      "Post: Theodor Herzl, the father of Zionism speaks\n",
      "Label (0=non-hate, 1=hate/polarizing): 0\n",
      "\n",
      "Example 5:\n",
      "Post: As Joe Biden leaves the White House today, I reflect on his life and legacy.\n",
      "Label (0=non-hate, 1=hate/polarizing): 0\n",
      "\n",
      "Example 6:\n",
      "Post: The 2025 shareholder meeting will be in a few months. Shareholders should definitely exercise their voti ...\n",
      "\n",
      "\n",
      "[T1] Running Qwen few-shot on TRAIN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T1] Qwen few-shot Macro-F1 on TRAIN (hard labels): 0.38849876636933006\n",
      "\n",
      "[T1] Running Qwen few-shot on DEV...\n",
      "Saved T1 TRAIN cache: cache/qwen5shots/eng/t1_train_probs.csv\n",
      "Saved T1 DEV cache  : cache/qwen5shots/eng/t1_dev_probs.csv\n",
      "Saved Qwen few-shot Subtask 1 submission: submissions/qwen5shots/subtask_1/pred_eng.csv\n"
     ]
    }
   ],
   "source": [
    "# ## Subtask 1 — Polarization (binary, Qwen few-shot)\n",
    "\n",
    "# 1. Load TRAIN + DEV\n",
    "t1_train_df = pd.read_csv(T1_TRAIN)\n",
    "t1_dev_df   = pd.read_csv(T1_DEV)\n",
    "\n",
    "required_train_cols_t1 = {\"id\", \"text\", \"polarization\"}\n",
    "required_dev_cols_t1   = {\"id\", \"text\"}\n",
    "assert required_train_cols_t1.issubset(t1_train_df.columns), \\\n",
    "    f\"T1 TRAIN missing: {required_train_cols_t1 - set(t1_train_df.columns)}\"\n",
    "assert required_dev_cols_t1.issubset(t1_dev_df.columns), \\\n",
    "    f\"T1 DEV missing: {required_dev_cols_t1 - set(t1_dev_df.columns)}\"\n",
    "\n",
    "t1_train_df[\"polarization\"] = t1_train_df[\"polarization\"].astype(int)\n",
    "\n",
    "print(f\"[T1] TRAIN size: {len(t1_train_df)}\")\n",
    "print(f\"[T1] DEV size  : {len(t1_dev_df)}\")\n",
    "\n",
    "# 2. Build few-shot context from TRAIN\n",
    "fewshot_ctx_t1 = build_fewshot_context_t1(t1_train_df, LANG, n_pos=3, n_neg=3)\n",
    "print(\"\\n[T1] Few-shot context (truncated):\\n\")\n",
    "print(fewshot_ctx_t1[:800], \"...\\n\")\n",
    "\n",
    "# 3. Build prompts for TRAIN and DEV\n",
    "train_prompts_t1 = [\n",
    "    build_prompt_t1(txt, LANG, fewshot_ctx_t1)\n",
    "    for txt in t1_train_df[\"text\"].astype(str).tolist()\n",
    "]\n",
    "dev_prompts_t1 = [\n",
    "    build_prompt_t1(txt, LANG, fewshot_ctx_t1)\n",
    "    for txt in t1_dev_df[\"text\"].astype(str).tolist()\n",
    "]\n",
    "\n",
    "# 4. Run Qwen on TRAIN\n",
    "print(\"\\n[T1] Running Qwen few-shot on TRAIN...\")\n",
    "train_outputs_t1 = qwen_generate_batch(\n",
    "    train_prompts_t1,\n",
    "    max_new_tokens=8,\n",
    "    batch_size=4,\n",
    ")\n",
    "pred_train_t1 = np.array([parse_t1_output(o) for o in train_outputs_t1], dtype=int)\n",
    "\n",
    "# 5. Evaluate on TRAIN\n",
    "y_true_t1 = t1_train_df[\"polarization\"].values\n",
    "f1_t1 = macro_f1(y_true_t1, pred_train_t1)\n",
    "print(\"[T1] Qwen few-shot Macro-F1 on TRAIN (hard labels):\", f1_t1)\n",
    "\n",
    "# 6. Run Qwen on DEV\n",
    "print(\"\\n[T1] Running Qwen few-shot on DEV...\")\n",
    "dev_outputs_t1 = qwen_generate_batch(\n",
    "    dev_prompts_t1,\n",
    "    max_new_tokens=8,\n",
    "    batch_size=4,\n",
    ")\n",
    "pred_dev_t1 = np.array([parse_t1_output(o) for o in dev_outputs_t1], dtype=int)\n",
    "\n",
    "# 7. Save caches for ensemble (treat Qwen prediction as prob 0/1)\n",
    "cache_t1_train = pd.DataFrame({\n",
    "    \"id\":       t1_train_df[\"id\"].astype(str).values,\n",
    "    \"prob_pos\": pred_train_t1.astype(float),  # 0.0 or 1.0\n",
    "    \"label\":    y_true_t1.astype(int),\n",
    "})\n",
    "cache_t1_dev = pd.DataFrame({\n",
    "    \"id\":       t1_dev_df[\"id\"].astype(str).values,\n",
    "    \"prob_pos\": pred_dev_t1.astype(float),\n",
    "})\n",
    "\n",
    "t1_train_cache_path = CACHE_ROOT / \"t1_train_probs.csv\"\n",
    "t1_dev_cache_path   = CACHE_ROOT / \"t1_dev_probs.csv\"\n",
    "cache_t1_train.to_csv(t1_train_cache_path, index=False)\n",
    "cache_t1_dev.to_csv(t1_dev_cache_path, index=False)\n",
    "\n",
    "print(\"Saved T1 TRAIN cache:\", t1_train_cache_path)\n",
    "print(\"Saved T1 DEV cache  :\", t1_dev_cache_path)\n",
    "\n",
    "sub1 = pd.DataFrame({\n",
    "    \"id\":           t1_dev_df[\"id\"].astype(str).values,\n",
    "    \"polarization\": pred_dev_t1.astype(int),\n",
    "})\n",
    "sub1_path = SUB_ROOT / \"subtask_1\" / f\"pred_{lang_fname}.csv\"\n",
    "sub1.to_csv(sub1_path, index=False)\n",
    "print(\"Saved Qwen few-shot Subtask 1 submission:\", sub1_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a1d29c",
   "metadata": {},
   "source": [
    "## Subtask 2 (multi-label 5, few-shot Qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f691944d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T2] TRAIN size: 3222\n",
      "[T2] DEV size  : 160\n",
      "\n",
      "[T2] Few-shot context (truncated):\n",
      "\n",
      "Example 1:\n",
      "Post: CriTiQuE gEnDeR iDeOLoGy harass trans people and their families\n",
      "Labels (gender/sexual, political, religious, racial/ethnic, other): 1 0 0 0 0\n",
      "\n",
      "Example 2:\n",
      "Post: Isnt there supposed to be proPalestine activists on this platform? Dont you want to say \"Free Palestine\" without getting banned?\n",
      "Labels (gender/sexual, political, religious, racial/ethnic, other): 0 1 0 0 0\n",
      "\n",
      "Example 3:\n",
      "Post: Christian nationalism is just fascism wrapped in a flag standing on a Bible, but all the pages of the Bible are blank.\n",
      "Labels (gender/sexual, political, religious, racial/ethnic, other): 0 0 1 0 0\n",
      "\n",
      "Example 4:\n",
      "Post: I mean he def puts the X in xenophobia.\n",
      "Labels (gender/sexual, political, religious, racial/ethnic, other): 0 0 0 1 0\n",
      "\n",
      "Example 5:\n",
      "Post: Its the NY Post. Theyre literally fake news.\n",
      "La ...\n",
      "\n",
      "\n",
      "[T2] Running Qwen few-shot on TRAIN...\n",
      "[T2] Qwen few-shot Macro-F1 on TRAIN (hard multi-label): 0.12739548651096502\n",
      "\n",
      "[T2] Running Qwen few-shot on DEV...\n",
      "Saved T2 TRAIN cache: cache/qwen5shots/eng/t2_train_probs.csv\n",
      "Saved T2 DEV cache  : cache/qwen5shots/eng/t2_dev_probs.csv\n",
      "Saved Qwen few-shot Subtask 2 submission: submissions/qwen5shots/subtask_2/pred_eng.csv\n"
     ]
    }
   ],
   "source": [
    "# ## Subtask 2 — Hate type (multi-label 5, Qwen few-shot)\n",
    "\n",
    "# 1. Load TRAIN + DEV\n",
    "t2_train_df = pd.read_csv(T2_TRAIN)\n",
    "t2_dev_df   = pd.read_csv(T2_DEV)\n",
    "\n",
    "required_train_cols_t2 = {\"id\", \"text\", *T2_LABELS}\n",
    "required_dev_cols_t2   = {\"id\", \"text\"}\n",
    "assert required_train_cols_t2.issubset(t2_train_df.columns), \\\n",
    "    f\"T2 TRAIN missing: {required_train_cols_t2 - set(t2_train_df.columns)}\"\n",
    "assert required_dev_cols_t2.issubset(t2_dev_df.columns), \\\n",
    "    f\"T2 DEV missing: {required_dev_cols_t2 - set(t2_dev_df.columns)}\"\n",
    "\n",
    "Y2_train = t2_train_df[T2_LABELS].values.astype(int)\n",
    "\n",
    "print(f\"[T2] TRAIN size: {len(t2_train_df)}\")\n",
    "print(f\"[T2] DEV size  : {len(t2_dev_df)}\")\n",
    "\n",
    "# 2. Build few-shot context from TRAIN (label-balanced)\n",
    "fewshot_ctx_t2 = build_fewshot_context_t2(\n",
    "    t2_train_df,\n",
    "    LANG,\n",
    "    max_examples_per_label=1,\n",
    "    n_negatives=2,\n",
    ")\n",
    "print(\"\\n[T2] Few-shot context (truncated):\\n\")\n",
    "print(fewshot_ctx_t2[:800], \"...\\n\")\n",
    "\n",
    "# 3. Build prompts\n",
    "train_prompts_t2 = [\n",
    "    build_prompt_t2(txt, LANG, fewshot_ctx_t2)\n",
    "    for txt in t2_train_df[\"text\"].astype(str).tolist()\n",
    "]\n",
    "dev_prompts_t2 = [\n",
    "    build_prompt_t2(txt, LANG, fewshot_ctx_t2)\n",
    "    for txt in t2_dev_df[\"text\"].astype(str).tolist()\n",
    "]\n",
    "\n",
    "# 4. Run Qwen on TRAIN\n",
    "print(\"\\n[T2] Running Qwen few-shot on TRAIN...\")\n",
    "train_outputs_t2 = qwen_generate_batch(\n",
    "    train_prompts_t2,\n",
    "    max_new_tokens=16,\n",
    "    batch_size=4,\n",
    ")\n",
    "pred_train_t2 = np.stack(\n",
    "    [parse_digit_vector(o, n_labels=len(T2_LABELS)) for o in train_outputs_t2],\n",
    "    axis=0,\n",
    ")  # [N,5]\n",
    "\n",
    "# 5. Evaluate on TRAIN (macro-F1 across labels)\n",
    "f1_t2 = f1_score(Y2_train, pred_train_t2, average=\"macro\", zero_division=0)\n",
    "print(\"[T2] Qwen few-shot Macro-F1 on TRAIN (hard multi-label):\", f1_t2)\n",
    "\n",
    "# 6. Run Qwen on DEV\n",
    "print(\"\\n[T2] Running Qwen few-shot on DEV...\")\n",
    "dev_outputs_t2 = qwen_generate_batch(\n",
    "    dev_prompts_t2,\n",
    "    max_new_tokens=16,\n",
    "    batch_size=4,\n",
    ")\n",
    "pred_dev_t2 = np.stack(\n",
    "    [parse_digit_vector(o, n_labels=len(T2_LABELS)) for o in dev_outputs_t2],\n",
    "    axis=0,\n",
    ")  # [N_dev,5]\n",
    "\n",
    "# 7. Save caches for ensemble (probabilities are just 0/1 from Qwen)\n",
    "cache_cols_train_t2 = {\n",
    "    \"id\": t2_train_df[\"id\"].astype(str).values\n",
    "}\n",
    "cache_cols_dev_t2 = {\n",
    "    \"id\": t2_dev_df[\"id\"].astype(str).values\n",
    "}\n",
    "\n",
    "for j, lab in enumerate(T2_LABELS):\n",
    "    cache_cols_train_t2[f\"prob_{lab}\"]  = pred_train_t2[:, j].astype(float)\n",
    "    cache_cols_train_t2[f\"label_{lab}\"] = Y2_train[:, j].astype(int)\n",
    "    cache_cols_dev_t2[f\"prob_{lab}\"]    = pred_dev_t2[:, j].astype(float)\n",
    "\n",
    "t2_train_cache = pd.DataFrame(cache_cols_train_t2)\n",
    "t2_dev_cache   = pd.DataFrame(cache_cols_dev_t2)\n",
    "\n",
    "t2_train_cache_path = CACHE_ROOT / \"t2_train_probs.csv\"\n",
    "t2_dev_cache_path   = CACHE_ROOT / \"t2_dev_probs.csv\"\n",
    "\n",
    "t2_train_cache.to_csv(t2_train_cache_path, index=False)\n",
    "t2_dev_cache.to_csv(t2_dev_cache_path, index=False)\n",
    "\n",
    "print(\"Saved T2 TRAIN cache:\", t2_train_cache_path)\n",
    "print(\"Saved T2 DEV cache  :\", t2_dev_cache_path)\n",
    "\n",
    "# Required header: id,political,racial/ethnic,religious,gender/sexual,other\n",
    "\n",
    "idx_gender    = T2_LABELS.index(\"gender/sexual\")\n",
    "idx_political = T2_LABELS.index(\"political\")\n",
    "idx_religious = T2_LABELS.index(\"religious\")\n",
    "idx_racial    = T2_LABELS.index(\"racial/ethnic\")\n",
    "idx_other     = T2_LABELS.index(\"other\")\n",
    "\n",
    "sub2 = pd.DataFrame({\n",
    "    \"id\":            t2_dev_df[\"id\"].astype(str).values,\n",
    "    \"political\":     pred_dev_t2[:, idx_political],\n",
    "    \"racial/ethnic\": pred_dev_t2[:, idx_racial],\n",
    "    \"religious\":     pred_dev_t2[:, idx_religious],\n",
    "    \"gender/sexual\": pred_dev_t2[:, idx_gender],\n",
    "    \"other\":         pred_dev_t2[:, idx_other],\n",
    "})\n",
    "sub2_path = SUB_ROOT / \"subtask_2\" / f\"pred_{lang_fname}.csv\"\n",
    "sub2.to_csv(sub2_path, index=False)\n",
    "print(\"Saved Qwen few-shot Subtask 2 submission:\", sub2_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a9e47",
   "metadata": {},
   "source": [
    "## Subtask 3 (multi-label 6, few-shot Qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cffa966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T3] TRAIN size: 3222\n",
      "[T3] DEV size  : 160\n",
      "\n",
      "[T3] Few-shot context (truncated):\n",
      "\n",
      "Example 1:\n",
      "Post: This is our border security, were waiting for the fat fascist whenever hes ready.\n",
      "Labels (vilification, extreme_language, stereotype, invalidation, lack_of_empathy, dehumanization): 1 0 0 0 0 0\n",
      "\n",
      "Example 2:\n",
      "Post: AMERICANS MUST TAKE TO THE STREETS IN SUPPORT OF ALL MILITARY AID TO THE UKRAINIANS!\n",
      "Labels (vilification, extreme_language, stereotype, invalidation, lack_of_empathy, dehumanization): 0 1 0 0 0 0\n",
      "\n",
      "Example 3:\n",
      "Post: Time for a lasting ceasefire. And arrest Netanyahu\n",
      "Labels (vilification, extreme_language, stereotype, invalidation, lack_of_empathy, dehumanization): 0 0 1 0 0 0\n",
      "\n",
      "Example 4:\n",
      "Post: YIAY2025 Donald Trump is unelected president\n",
      "Labels (vilification, extreme_language, stereotype, invalidation, lack_of_empathy, dehumanization): 0 0 0 1 0 0\n",
      "\n",
      "Example 5:\n",
      "Post:  ...\n",
      "\n",
      "\n",
      "[T3] Running Qwen few-shot on TRAIN...\n",
      "[T3] Qwen few-shot Macro-F1 on TRAIN (hard multi-label): 0.17816070899669703\n",
      "\n",
      "[T3] Running Qwen few-shot on DEV...\n",
      "Saved T3 TRAIN cache: cache/qwen5shots/eng/t3_train_probs.csv\n",
      "Saved T3 DEV cache  : cache/qwen5shots/eng/t3_dev_probs.csv\n",
      "Saved Qwen few-shot Subtask 3 submission: submissions/qwen5shots/subtask_3/pred_eng.csv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ## Subtask 3 — Manifestation (multi-label 6, Qwen few-shot)\n",
    "\n",
    "# 1. Load TRAIN + DEV\n",
    "t3_train_df = pd.read_csv(T3_TRAIN)\n",
    "t3_dev_df   = pd.read_csv(T3_DEV)\n",
    "\n",
    "required_train_cols_t3 = {\"id\", \"text\", *T3_LABELS}\n",
    "required_dev_cols_t3   = {\"id\", \"text\"}\n",
    "assert required_train_cols_t3.issubset(t3_train_df.columns), \\\n",
    "    f\"T3 TRAIN missing: {required_train_cols_t3 - set(t3_train_df.columns)}\"\n",
    "assert required_dev_cols_t3.issubset(t3_dev_df.columns), \\\n",
    "    f\"T3 DEV missing: {required_dev_cols_t3 - set(t3_dev_df.columns)}\"\n",
    "\n",
    "Y3_train = t3_train_df[T3_LABELS].values.astype(int)\n",
    "\n",
    "print(f\"[T3] TRAIN size: {len(t3_train_df)}\")\n",
    "print(f\"[T3] DEV size  : {len(t3_dev_df)}\")\n",
    "\n",
    "# 2. Build few-shot context from TRAIN (label-balanced)\n",
    "fewshot_ctx_t3 = build_fewshot_context_t3(\n",
    "    t3_train_df,\n",
    "    LANG,\n",
    "    max_examples_per_label=1,\n",
    "    n_negatives=2,\n",
    ")\n",
    "print(\"\\n[T3] Few-shot context (truncated):\\n\")\n",
    "print(fewshot_ctx_t3[:800], \"...\\n\")\n",
    "\n",
    "# 3. Build prompts\n",
    "train_prompts_t3 = [\n",
    "    build_prompt_t3(txt, LANG, fewshot_ctx_t3)\n",
    "    for txt in t3_train_df[\"text\"].astype(str).tolist()\n",
    "]\n",
    "dev_prompts_t3 = [\n",
    "    build_prompt_t3(txt, LANG, fewshot_ctx_t3)\n",
    "    for txt in t3_dev_df[\"text\"].astype(str).tolist()\n",
    "]\n",
    "\n",
    "# 4. Run Qwen on TRAIN\n",
    "print(\"\\n[T3] Running Qwen few-shot on TRAIN...\")\n",
    "train_outputs_t3 = qwen_generate_batch(\n",
    "    train_prompts_t3,\n",
    "    max_new_tokens=16,\n",
    "    batch_size=4,\n",
    ")\n",
    "pred_train_t3 = np.stack(\n",
    "    [parse_digit_vector(o, n_labels=len(T3_LABELS)) for o in train_outputs_t3],\n",
    "    axis=0,\n",
    ")  # [N,6]\n",
    "\n",
    "# 5. Evaluate on TRAIN\n",
    "f1_t3 = f1_score(Y3_train, pred_train_t3, average=\"macro\", zero_division=0)\n",
    "print(\"[T3] Qwen few-shot Macro-F1 on TRAIN (hard multi-label):\", f1_t3)\n",
    "\n",
    "# 6. Run Qwen on DEV\n",
    "print(\"\\n[T3] Running Qwen few-shot on DEV...\")\n",
    "dev_outputs_t3 = qwen_generate_batch(\n",
    "    dev_prompts_t3,\n",
    "    max_new_tokens=16,\n",
    "    batch_size=4,\n",
    ")\n",
    "pred_dev_t3 = np.stack(\n",
    "    [parse_digit_vector(o, n_labels=len(T3_LABELS)) for o in dev_outputs_t3],\n",
    "    axis=0,\n",
    ")  # [N_dev,6]\n",
    "\n",
    "# 7. Save caches for ensemble\n",
    "cache_cols_train_t3 = {\n",
    "    \"id\": t3_train_df[\"id\"].astype(str).values\n",
    "}\n",
    "cache_cols_dev_t3 = {\n",
    "    \"id\": t3_dev_df[\"id\"].astype(str).values\n",
    "}\n",
    "\n",
    "for j, lab in enumerate(T3_LABELS):\n",
    "    cache_cols_train_t3[f\"prob_{lab}\"]  = pred_train_t3[:, j].astype(float)\n",
    "    cache_cols_train_t3[f\"label_{lab}\"] = Y3_train[:, j].astype(int)\n",
    "    cache_cols_dev_t3[f\"prob_{lab}\"]    = pred_dev_t3[:, j].astype(float)\n",
    "\n",
    "t3_train_cache = pd.DataFrame(cache_cols_train_t3)\n",
    "t3_dev_cache   = pd.DataFrame(cache_cols_dev_t3)\n",
    "\n",
    "t3_train_cache_path = CACHE_ROOT / \"t3_train_probs.csv\"\n",
    "t3_dev_cache_path   = CACHE_ROOT / \"t3_dev_probs.csv\"\n",
    "\n",
    "t3_train_cache.to_csv(t3_train_cache_path, index=False)\n",
    "t3_dev_cache.to_csv(t3_dev_cache_path, index=False)\n",
    "\n",
    "print(\"Saved T3 TRAIN cache:\", t3_train_cache_path)\n",
    "print(\"Saved T3 DEV cache  :\", t3_dev_cache_path)\n",
    "\n",
    "# Required header:\n",
    "#   id,stereotype,vilification,dehumanization,\n",
    "#   extreme_language,lack_of_empathy,invalidation\n",
    "\n",
    "idx_vil      = T3_LABELS.index(\"vilification\")\n",
    "idx_extreme  = T3_LABELS.index(\"extreme_language\")\n",
    "idx_stereo   = T3_LABELS.index(\"stereotype\")\n",
    "idx_invalid  = T3_LABELS.index(\"invalidation\")\n",
    "idx_lackemp  = T3_LABELS.index(\"lack_of_empathy\")\n",
    "idx_dehum    = T3_LABELS.index(\"dehumanization\")\n",
    "\n",
    "sub3 = pd.DataFrame({\n",
    "    \"id\":               t3_dev_df[\"id\"].astype(str).values,\n",
    "    \"stereotype\":       pred_dev_t3[:, idx_stereo],\n",
    "    \"vilification\":     pred_dev_t3[:, idx_vil],\n",
    "    \"dehumanization\":   pred_dev_t3[:, idx_dehum],\n",
    "    \"extreme_language\": pred_dev_t3[:, idx_extreme],\n",
    "    \"lack_of_empathy\":  pred_dev_t3[:, idx_lackemp],\n",
    "    \"invalidation\":     pred_dev_t3[:, idx_invalid],\n",
    "})\n",
    "sub3_path = SUB_ROOT / \"subtask_3\" / f\"pred_{lang_fname}.csv\"\n",
    "sub3.to_csv(sub3_path, index=False)\n",
    "print(\"Saved Qwen few-shot Subtask 3 submission:\", sub3_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
