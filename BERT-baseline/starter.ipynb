{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "78d203c2-4edd-41ed-a45d-dc1fc92fa697",
      "metadata": {
        "id": "78d203c2-4edd-41ed-a45d-dc1fc92fa697"
      },
      "source": [
        "# Bert baseline for POLAR"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea01ed9f-399e-4b8a-b46f-49369a33ee31",
      "metadata": {
        "id": "ea01ed9f-399e-4b8a-b46f-49369a33ee31"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this part of the starter notebook, we will take you through the process of all three Subtasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aIt64l96d4TR",
      "metadata": {
        "id": "aIt64l96d4TR"
      },
      "source": [
        "## Subtask 1 - Polarization detection\n",
        "\n",
        "This is a binary classification to determine whether a post contains polarized content (Polarized or Not Polarized)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e5w0WSE89hdW",
      "metadata": {
        "id": "e5w0WSE89hdW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open dev_phase.zip, dev_phase.zip.zip or dev_phase.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip dev_phase.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "843cbd77-1b7f-41df-aec8-1d53fe1199c2",
      "metadata": {
        "id": "843cbd77-1b7f-41df-aec8-1d53fe1199c2"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "49598b60",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "  Using cached pandas-2.3.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (91 kB)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /Users/shahriar/.venvs/nlp/lib/python3.9/site-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/shahriar/.venvs/nlp/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /Users/shahriar/.venvs/nlp/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Using cached pandas-2.3.3-cp39-cp39-macosx_11_0_arm64.whl (10.8 MB)\n",
            "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Installing collected packages: pytz, tzdata, pandas\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [pandas]2m2/3\u001b[0m [pandas]\n",
            "\u001b[1A\u001b[2KSuccessfully installed pandas-2.3.3 pytz-2025.2 tzdata-2025.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5b8e9d6e-9342-43fd-9a0a-1330caf4e23a",
      "metadata": {
        "id": "5b8e9d6e-9342-43fd-9a0a-1330caf4e23a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n",
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2e30ed73",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.22.3-py3-none-macosx_12_0_arm64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typing_extensions in /Users/shahriar/.venvs/nlp/lib/python3.9/site-packages (4.15.0)\n",
            "Collecting click>=8.0.1 (from wandb)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting eval-type-backport (from wandb)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging in /Users/shahriar/.venvs/nlp/lib/python3.9/site-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /Users/shahriar/.venvs/nlp/lib/python3.9/site-packages (from wandb) (4.4.0)\n",
            "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 (from wandb)\n",
            "  Downloading protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
            "Collecting pydantic<3 (from wandb)\n",
            "  Downloading pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
            "Requirement already satisfied: pyyaml in /Users/shahriar/.venvs/nlp/lib/python3.9/site-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /Users/shahriar/.venvs/nlp/lib/python3.9/site-packages (from wandb) (2.32.5)\n",
            "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.43.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.4 (from pydantic<3->wandb)\n",
            "  Downloading pydantic_core-2.41.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic<3->wandb)\n",
            "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/shahriar/.venvs/nlp/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/shahriar/.venvs/nlp/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shahriar/.venvs/nlp/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/shahriar/.venvs/nlp/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading wandb-0.22.3-py3-none-macosx_12_0_arm64.whl (18.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.8/18.8 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
            "Downloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
            "Downloading pydantic_core-2.41.4-cp39-cp39-macosx_11_0_arm64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
            "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Downloading sentry_sdk-2.43.0-py2.py3-none-any.whl (400 kB)\n",
            "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: typing-inspection, smmap, sentry-sdk, pydantic-core, protobuf, eval-type-backport, click, annotated-types, pydantic, gitdb, gitpython, wandb\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12/12\u001b[0m [wandb]m11/12\u001b[0m [wandb]ic]k]\n",
            "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 click-8.1.8 eval-type-backport-0.2.2 gitdb-4.0.12 gitpython-3.1.45 protobuf-6.33.0 pydantic-2.12.3 pydantic-core-2.41.4 sentry-sdk-2.43.0 smmap-5.0.2 typing-inspection-0.4.2 wandb-0.22.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip uninstall -y wandb\n",
        "%pip install --no-cache-dir --upgrade wandb typing_extensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "UkC2r47nManC",
      "metadata": {
        "id": "UkC2r47nManC"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/ck7f2sv5?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x179f92a90>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "# Disable wandb logging for this script\n",
        "wandb.init(mode=\"disabled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dac92ad-3fac-4aa1-aae6-1fe3ad14b1c0",
      "metadata": {
        "id": "4dac92ad-3fac-4aa1-aae6-1fe3ad14b1c0"
      },
      "source": [
        "## Data Import\n",
        "\n",
        "The training data consists of a short text and binary labels\n",
        "\n",
        "The data is structured as a CSV file with the following fields:\n",
        "- id: a unique identifier for the sample\n",
        "- text: a sentence or short text\n",
        "- polarization:  1 text is polarized, 0 text is not polarized\n",
        "\n",
        "The data is in all three subtask folders the same but only containing the labels for the specific task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4fe8cc2-ba47-4240-bdd2-b1d3ea323134",
      "metadata": {
        "id": "e4fe8cc2-ba47-4240-bdd2-b1d3ea323134"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "      <th>id</th>\n",
              "      <th>polarization</th>\n",
              "      <th>political</th>\n",
              "      <th>racial/ethnic</th>\n",
              "      <th>religious</th>\n",
              "      <th>gender/sexual</th>\n",
              "      <th>other</th>\n",
              "      <th>stereotype</th>\n",
              "      <th>vilification</th>\n",
              "      <th>dehumanization</th>\n",
              "      <th>extreme_language</th>\n",
              "      <th>lack_of_empathy</th>\n",
              "      <th>invalidation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The EU is increasing military aid to Ukraine t...</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng_dbcee818b240e8ea82a37e5530738aa7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>House drafts bill to strike Iran proxies amid ...</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng_0fe6a37502da8f89af480449d5352c7f</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Contested races across county early voting</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng_8cec277cafb320e79bf8ed5632529b9d</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dem bill would hold West Bank settlers account...</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng_b1493ef1e1a5e3109d8a211a28283ee8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Local woman gets a death threat after flying T...</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng_a5f34a5db504fc4801152156897b2c4d</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text lang  \\\n",
              "0  The EU is increasing military aid to Ukraine t...  eng   \n",
              "1  House drafts bill to strike Iran proxies amid ...  eng   \n",
              "2         Contested races across county early voting  eng   \n",
              "3  Dem bill would hold West Bank settlers account...  eng   \n",
              "4  Local woman gets a death threat after flying T...  eng   \n",
              "\n",
              "                                     id  polarization  political  \\\n",
              "0  eng_dbcee818b240e8ea82a37e5530738aa7             0          0   \n",
              "1  eng_0fe6a37502da8f89af480449d5352c7f             0          0   \n",
              "2  eng_8cec277cafb320e79bf8ed5632529b9d             0          0   \n",
              "3  eng_b1493ef1e1a5e3109d8a211a28283ee8             0          0   \n",
              "4  eng_a5f34a5db504fc4801152156897b2c4d             0          0   \n",
              "\n",
              "   racial/ethnic  religious  gender/sexual  other  stereotype  vilification  \\\n",
              "0              0          0              0      0           0             0   \n",
              "1              0          0              0      0           0             0   \n",
              "2              0          0              0      0           0             0   \n",
              "3              0          0              0      0           0             0   \n",
              "4              0          0              0      0           0             0   \n",
              "\n",
              "   dehumanization  extreme_language  lack_of_empathy  invalidation  \n",
              "0               0                 0                0             0  \n",
              "1               0                 0                0             0  \n",
              "2               0                 0                0             0  \n",
              "3               0                 0                0             0  \n",
              "4               0                 0                0             0  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the training and validation data for subtask 1\n",
        "\n",
        "train = pd.read_csv('../dev_phase/subtask1/train/eng.csv')\n",
        "val = pd.read_csv('../dev_phase/subtask1/train/eng.csv')\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eQWDFio83z9g",
      "metadata": {
        "id": "eQWDFio83z9g"
      },
      "source": [
        "# Dataset\n",
        "-  Create a pytorch class for handling data\n",
        "-  Wrapping the raw texts and labels into a format that Huggingface‚Äôs Trainer can use for training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8e749d08",
      "metadata": {
        "id": "8e749d08"
      },
      "outputs": [],
      "source": [
        "# Fix the dataset class by inheriting from torch.utils.data.Dataset\n",
        "class PolarizationDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,texts,labels,tokenizer,max_length =128):\n",
        "    self.texts=texts\n",
        "    self.labels=labels\n",
        "    self.tokenizer= tokenizer\n",
        "    self.max_length = max_length # Store max_length\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    text=self.texts[idx]\n",
        "    label=self.labels[idx]\n",
        "    encoding=self.tokenizer(text,truncation=True,padding=False,max_length=self.max_length,return_tensors='pt')\n",
        "\n",
        "    # Ensure consistent tensor conversion for all items\n",
        "    item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "    item['labels'] = torch.tensor(label, dtype=torch.long)\n",
        "    return item"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adfb74a3",
      "metadata": {
        "id": "adfb74a3"
      },
      "source": [
        "Now, we'll tokenize the text data and create the datasets using `bert-base-uncased` as the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c2e6215b",
      "metadata": {
        "id": "c2e6215b"
      },
      "outputs": [],
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = PolarizationDataset(train['text'].tolist(), train['polarization'].tolist(), tokenizer)\n",
        "val_dataset = PolarizationDataset(val['text'].tolist(), val['polarization'].tolist(), tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b13caa5c",
      "metadata": {
        "id": "b13caa5c"
      },
      "source": [
        "Next, we'll load the pre-trained `bert-base-uncased` model for sequence classification. Since this is a binary classification task (Polarized/Not Polarized), we set `num_labels=2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7cd0411f",
      "metadata": {
        "id": "7cd0411f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b250d61e",
      "metadata": {
        "id": "b250d61e"
      },
      "source": [
        "Now, we'll define the training arguments and the evaluation metric. We'll use macro F1 score for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "21c97269",
      "metadata": {
        "id": "21c97269"
      },
      "outputs": [],
      "source": [
        "# Define metrics function\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    return {'f1_macro': f1_score(p.label_ids, preds, average='macro')}\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "        output_dir=f\"./\",\n",
        "        num_train_epochs=3,\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=64,\n",
        "        per_device_eval_batch_size=8,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"no\",\n",
        "        logging_steps=100,\n",
        "        disable_tqdm=False\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20167a2b",
      "metadata": {
        "id": "20167a2b"
      },
      "source": [
        "Finally, we'll initialize the `Trainer` and start training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ecd9f444",
      "metadata": {
        "id": "ecd9f444"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:02, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.692492</td>\n",
              "      <td>0.310345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.641752</td>\n",
              "      <td>0.560440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.616530</td>\n",
              "      <td>0.560440</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1 score on validation set: 0.5604395604395604\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated ü§ó Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
        "    data_collator=DataCollatorWithPadding(tokenizer) # Data collator for dynamic padding\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Macro F1 score on validation set: {eval_results['eval_f1_macro']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5Qi53eheGIbu",
      "metadata": {
        "id": "5Qi53eheGIbu"
      },
      "source": [
        "# Subtask 2: Polarization Type Classification\n",
        "Multi-label classification to identify the target of polarization as one of the following categories: Gender/Sexual, Political, Religious, Racial/Ethnic, or Other.\n",
        "For this task we will load the data for subtask 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YaWIvnYv0rV2",
      "metadata": {
        "id": "YaWIvnYv0rV2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "      <th>id</th>\n",
              "      <th>polarization</th>\n",
              "      <th>political</th>\n",
              "      <th>racial/ethnic</th>\n",
              "      <th>religious</th>\n",
              "      <th>gender/sexual</th>\n",
              "      <th>other</th>\n",
              "      <th>stereotype</th>\n",
              "      <th>vilification</th>\n",
              "      <th>dehumanization</th>\n",
              "      <th>extreme_language</th>\n",
              "      <th>lack_of_empathy</th>\n",
              "      <th>invalidation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The EU is increasing military aid to Ukraine t...</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng_dbcee818b240e8ea82a37e5530738aa7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>House drafts bill to strike Iran proxies amid ...</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng_0fe6a37502da8f89af480449d5352c7f</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Contested races across county early voting</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng_8cec277cafb320e79bf8ed5632529b9d</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dem bill would hold West Bank settlers account...</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng_b1493ef1e1a5e3109d8a211a28283ee8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Local woman gets a death threat after flying T...</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng_a5f34a5db504fc4801152156897b2c4d</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text lang  \\\n",
              "0  The EU is increasing military aid to Ukraine t...  eng   \n",
              "1  House drafts bill to strike Iran proxies amid ...  eng   \n",
              "2         Contested races across county early voting  eng   \n",
              "3  Dem bill would hold West Bank settlers account...  eng   \n",
              "4  Local woman gets a death threat after flying T...  eng   \n",
              "\n",
              "                                     id  polarization  political  \\\n",
              "0  eng_dbcee818b240e8ea82a37e5530738aa7             0          0   \n",
              "1  eng_0fe6a37502da8f89af480449d5352c7f             0          0   \n",
              "2  eng_8cec277cafb320e79bf8ed5632529b9d             0          0   \n",
              "3  eng_b1493ef1e1a5e3109d8a211a28283ee8             0          0   \n",
              "4  eng_a5f34a5db504fc4801152156897b2c4d             0          0   \n",
              "\n",
              "   racial/ethnic  religious  gender/sexual  other  stereotype  vilification  \\\n",
              "0              0          0              0      0           0             0   \n",
              "1              0          0              0      0           0             0   \n",
              "2              0          0              0      0           0             0   \n",
              "3              0          0              0      0           0             0   \n",
              "4              0          0              0      0           0             0   \n",
              "\n",
              "   dehumanization  extreme_language  lack_of_empathy  invalidation  \n",
              "0               0                 0                0             0  \n",
              "1               0                 0                0             0  \n",
              "2               0                 0                0             0  \n",
              "3               0                 0                0             0  \n",
              "4               0                 0                0             0  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv('../dev_phase/subtask2/train/eng.csv')\n",
        "val = pd.read_csv('../dev_phase/subtask2/train/eng.csv')\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "I6S2S6QBDKzw",
      "metadata": {
        "id": "I6S2S6QBDKzw"
      },
      "outputs": [],
      "source": [
        "# Fix the dataset class by inheriting from torch.utils.data.Dataset\n",
        "class PolarizationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length # Store max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(text, truncation=True, padding=False, max_length=self.max_length, return_tensors='pt')\n",
        "\n",
        "        # Ensure consistent tensor conversion for all items\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        # CHANGE THIS LINE: Use torch.float instead of torch.long for multi-label classification\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.float)\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "u1_KYsG68nxI",
      "metadata": {
        "id": "u1_KYsG68nxI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Create train and Test dataset for multilabel\n",
        "train_dataset = PolarizationDataset(train['text'].tolist(), train[['gender/sexual','political','religious','racial/ethnic','other']].values.tolist(), tokenizer)\n",
        "val_dataset = PolarizationDataset(val['text'].tolist(), val[['gender/sexual','political','religious','racial/ethnic','other']].values.tolist(), tokenizer)\n",
        "dev_dataset = PolarizationDataset(val['text'].tolist(), val[['gender/sexual','political','religious','racial/ethnic','other']].values.tolist(), tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "cdiYJyr08bw2",
      "metadata": {
        "id": "cdiYJyr08bw2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5, problem_type=\"multi_label_classification\") # 5 labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ArVWKwze2mtS",
      "metadata": {
        "id": "ArVWKwze2mtS"
      },
      "outputs": [],
      "source": [
        "# Define metrics function for multi-label classification\n",
        "def compute_metrics_multilabel(p):\n",
        "    # Sigmoid the predictions to get probabilities\n",
        "    probs = torch.sigmoid(torch.from_numpy(p.predictions))\n",
        "    # Convert probabilities to predicted labels (0 or 1)\n",
        "    preds = (probs > 0.5).int().numpy()\n",
        "    # Compute macro F1 score\n",
        "    return {'f1_macro': f1_score(p.label_ids, preds, average='macro')}\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"./\",\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    logging_steps=100,\n",
        "    disable_tqdm=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "Qd3QPyfc2RKE",
      "metadata": {
        "id": "Qd3QPyfc2RKE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A ConfigError was raised whilst setting the number of model parameters in Weights & Biases config.\n",
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:04, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.642059</td>\n",
              "      <td>0.165714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.606076</td>\n",
              "      <td>0.182011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.589351</td>\n",
              "      <td>0.186667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1 score on validation set for Subtask 2: 0.18666666666666668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics_multilabel,  # Use the new metrics function\n",
        "    data_collator=DataCollatorWithPadding(tokenizer)\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Macro F1 score on validation set for Subtask 2: {eval_results['eval_f1_macro']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UL1uE8llIgTQ",
      "metadata": {
        "id": "UL1uE8llIgTQ"
      },
      "source": [
        "# Subtask 3: Manifestation Identification\n",
        "Multi-label classification to classify how polarization is expressed, with multiple possible labels including Vilification, Extreme Language, Stereotype, Invalidation, Lack of Empathy, and Dehumanization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nCz20cgl-K3t",
      "metadata": {
        "id": "nCz20cgl-K3t"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "      <th>id</th>\n",
              "      <th>polarization</th>\n",
              "      <th>political</th>\n",
              "      <th>racial/ethnic</th>\n",
              "      <th>religious</th>\n",
              "      <th>gender/sexual</th>\n",
              "      <th>other</th>\n",
              "      <th>stereotype</th>\n",
              "      <th>vilification</th>\n",
              "      <th>dehumanization</th>\n",
              "      <th>extreme_language</th>\n",
              "      <th>lack_of_empathy</th>\n",
              "      <th>invalidation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The EU is increasing military aid to Ukraine t...</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng_dbcee818b240e8ea82a37e5530738aa7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>House drafts bill to strike Iran proxies amid ...</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng_0fe6a37502da8f89af480449d5352c7f</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Contested races across county early voting</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng_8cec277cafb320e79bf8ed5632529b9d</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dem bill would hold West Bank settlers account...</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng_b1493ef1e1a5e3109d8a211a28283ee8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Local woman gets a death threat after flying T...</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng_a5f34a5db504fc4801152156897b2c4d</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text lang  \\\n",
              "0  The EU is increasing military aid to Ukraine t...  eng   \n",
              "1  House drafts bill to strike Iran proxies amid ...  eng   \n",
              "2         Contested races across county early voting  eng   \n",
              "3  Dem bill would hold West Bank settlers account...  eng   \n",
              "4  Local woman gets a death threat after flying T...  eng   \n",
              "\n",
              "                                     id  polarization  political  \\\n",
              "0  eng_dbcee818b240e8ea82a37e5530738aa7             0          0   \n",
              "1  eng_0fe6a37502da8f89af480449d5352c7f             0          0   \n",
              "2  eng_8cec277cafb320e79bf8ed5632529b9d             0          0   \n",
              "3  eng_b1493ef1e1a5e3109d8a211a28283ee8             0          0   \n",
              "4  eng_a5f34a5db504fc4801152156897b2c4d             0          0   \n",
              "\n",
              "   racial/ethnic  religious  gender/sexual  other  stereotype  vilification  \\\n",
              "0              0          0              0      0           0             0   \n",
              "1              0          0              0      0           0             0   \n",
              "2              0          0              0      0           0             0   \n",
              "3              0          0              0      0           0             0   \n",
              "4              0          0              0      0           0             0   \n",
              "\n",
              "   dehumanization  extreme_language  lack_of_empathy  invalidation  \n",
              "0               0                 0                0             0  \n",
              "1               0                 0                0             0  \n",
              "2               0                 0                0             0  \n",
              "3               0                 0                0             0  \n",
              "4               0                 0                0             0  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv('../dev_phase/subtask3/train/eng.csv')\n",
        "val = pd.read_csv('../dev_phase/subtask3/train/eng.csv')\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "Qs-UjVYsInpD",
      "metadata": {
        "id": "Qs-UjVYsInpD"
      },
      "outputs": [],
      "source": [
        "# Fix the dataset class by inheriting from torch.utils.data.Dataset\n",
        "class PolarizationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length # Store max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(text, truncation=True, padding=False, max_length=self.max_length, return_tensors='pt')\n",
        "\n",
        "        # Ensure consistent tensor conversion for all items\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        # CHANGE THIS LINE: Use torch.float instead of torch.long for multi-label classification\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.float)\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "-yxSaDCA9IMi",
      "metadata": {
        "id": "-yxSaDCA9IMi"
      },
      "outputs": [],
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Create train and Test dataset for multilabel\n",
        "train_dataset = PolarizationDataset(train['text'].tolist(), train[['vilification','extreme_language','stereotype','invalidation','lack_of_empathy','dehumanization']].values.tolist(), tokenizer)\n",
        "val_dataset = PolarizationDataset(val['text'].tolist(), val[['vilification','extreme_language','stereotype','invalidation','lack_of_empathy','dehumanization']].values.tolist(), tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0VXqqqIH9A3M",
      "metadata": {
        "id": "0VXqqqIH9A3M"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6, problem_type=\"multi_label_classification\") # use 6 labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "QLubGtx988hm",
      "metadata": {
        "id": "QLubGtx988hm"
      },
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"./\",\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    logging_steps=100,\n",
        "    disable_tqdm=False\n",
        ")\n",
        "\n",
        "# Define metrics function for multi-label classification\n",
        "def compute_metrics_multilabel(p):\n",
        "    # Sigmoid the predictions to get probabilities\n",
        "    probs = torch.sigmoid(torch.from_numpy(p.predictions))\n",
        "    # Convert probabilities to predicted labels (0 or 1)\n",
        "    preds = (probs > 0.5).int().numpy()\n",
        "    # Compute macro F1 score\n",
        "    return {'f1_macro': f1_score(p.label_ids, preds, average='macro')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "qEhm1TEv82mP",
      "metadata": {
        "id": "qEhm1TEv82mP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A ConfigError was raised whilst setting the number of model parameters in Weights & Biases config.\n",
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:02, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.674196</td>\n",
              "      <td>0.273345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.631911</td>\n",
              "      <td>0.296667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.615305</td>\n",
              "      <td>0.303157</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/Users/shahriar/.venvs/nlp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1 score on validation set for Subtask 3: 0.30315698793959667\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics_multilabel,  # Use the new metrics function\n",
        "    data_collator=DataCollatorWithPadding(tokenizer)\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Macro F1 score on validation set for Subtask 3: {eval_results['eval_f1_macro']}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
