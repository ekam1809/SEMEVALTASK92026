{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a77bb249",
   "metadata": {},
   "source": [
    "## Setup — imports, config, paths (CPU-only, cache-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37075a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LANG = eng\n",
      "XLMR cache: cache/xlmr/eng\n",
      "DeBERTa cache: cache/deberta/eng\n",
      "Ensemble submissions root: submissions/ensemble\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0) Setup — imports, config, paths (CPU-only, cache-based)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ---- Hard-force CPU-ish env (not strictly needed, but safe) ----\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ[\"ACCELERATE_USE_CPU\"] = \"1\"\n",
    "os.environ[\"HF_ACCELERATE_USE_CPU\"] = \"1\"\n",
    "os.environ[\"USE_TORCH_MPS\"] = \"0\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# ======= Config you can edit =======\n",
    "LANG = \"eng\"          # e.g. \"eng\", \"ben\", \"hin\", ...\n",
    "\n",
    "# label orders (must match training notebooks)\n",
    "T2_LABELS = [\"gender/sexual\", \"political\", \"religious\", \"racial/ethnic\", \"other\"]\n",
    "T3_LABELS = [\n",
    "    \"vilification\", \"extreme_language\", \"stereotype\",\n",
    "    \"invalidation\", \"lack_of_empathy\", \"dehumanization\"\n",
    "]\n",
    "\n",
    "lang_fname = LANG\n",
    "\n",
    "# Roots for each method\n",
    "XLMR_ART_ROOT   = Path(\"artifacts\") / \"xlmr\" / LANG\n",
    "DEBERTA_ART_ROOT= Path(\"artifacts\") / \"deberta\" / LANG\n",
    "\n",
    "XLMR_CACHE_ROOT   = Path(\"cache\") / \"xlmr\" / LANG\n",
    "DEBERTA_CACHE_ROOT= Path(\"cache\") / \"deberta\" / LANG\n",
    "\n",
    "# Ensemble submission root\n",
    "SUB_ROOT_ENS = Path(\"submissions\") / \"ensemble\"\n",
    "for sub in [\"subtask_1\", \"subtask_2\", \"subtask_3\"]:\n",
    "    (SUB_ROOT_ENS / sub).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Using LANG =\", LANG)\n",
    "print(\"XLMR cache:\", XLMR_CACHE_ROOT)\n",
    "print(\"DeBERTa cache:\", DEBERTA_CACHE_ROOT)\n",
    "print(\"Ensemble submissions root:\", SUB_ROOT_ENS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4742615",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdce9808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) Helpers\n",
    "# ============================================================\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "def load_json(path: Path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98265631",
   "metadata": {},
   "source": [
    "## Subtask 1 — Polarization (binary), ensemble on TRAIN+DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "077143c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Subtask 1 (polarization) ====================\n",
      "T1 train merged shape: (3222, 5)\n",
      "XLMR T1 threshold=0.450\n",
      "DeBERTa T1 threshold=0.350\n",
      "Ensemble T1 threshold (avg)=0.400\n",
      "T1 Macro-F1 (TRAIN) XLMR:    0.8370522654243957\n",
      "T1 Macro-F1 (TRAIN) DeBERTa: 0.9552514501844848\n",
      "T1 Macro-F1 (TRAIN) ENS:     0.935225374944574\n",
      "T1 dev merged shape: (160, 3)\n",
      "Subtask 1 ensemble submission written to: submissions/ensemble/subtask_1/pred_eng.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2) Subtask 1 — Polarization (binary), ensemble on TRAIN+DEV\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n==================== Subtask 1 (polarization) ====================\")\n",
    "\n",
    "# 2.1 Load cached calibrated probabilities for TRAIN\n",
    "t1_train_x = pd.read_csv(XLMR_CACHE_ROOT / \"t1_train_probs.csv\")   # id, prob_pos, label\n",
    "t1_train_d = pd.read_csv(DEBERTA_CACHE_ROOT / \"t1_train_probs.csv\")\n",
    "\n",
    "t1_train = t1_train_x.merge(\n",
    "    t1_train_d, on=\"id\", suffixes=(\"_xlmr\", \"_deberta\")\n",
    ")\n",
    "print(\"T1 train merged shape:\", t1_train.shape)\n",
    "\n",
    "y_train_t1 = t1_train[\"label_xlmr\"].astype(int).values  # should match label_deberta\n",
    "\n",
    "p_x_t1 = t1_train[\"prob_pos_xlmr\"].values\n",
    "p_d_t1 = t1_train[\"prob_pos_deberta\"].values\n",
    "\n",
    "# 2.2 Load per-model calibration thresholds\n",
    "cal_x_t1 = load_json(XLMR_ART_ROOT / \"calib_t1_native.json\")\n",
    "cal_d_t1 = load_json(DEBERTA_ART_ROOT / \"calib_t1_native.json\")\n",
    "\n",
    "thr_x_t1 = float(cal_x_t1[\"threshold\"])\n",
    "thr_d_t1 = float(cal_d_t1[\"threshold\"])\n",
    "thr_ens_t1 = (thr_x_t1 + thr_d_t1) / 2.0\n",
    "\n",
    "print(f\"XLMR T1 threshold={thr_x_t1:.3f}\")\n",
    "print(f\"DeBERTa T1 threshold={thr_d_t1:.3f}\")\n",
    "print(f\"Ensemble T1 threshold (avg)={thr_ens_t1:.3f}\")\n",
    "\n",
    "# 2.3 TRAIN F1: XLMR, DeBERTa, Ensemble\n",
    "pred_x_train_t1 = (p_x_t1 >= thr_x_t1).astype(int)\n",
    "pred_d_train_t1 = (p_d_t1 >= thr_d_t1).astype(int)\n",
    "p_ens_train_t1 = 0.5 * (p_x_t1 + p_d_t1)\n",
    "pred_ens_train_t1 = (p_ens_train_t1 >= thr_ens_t1).astype(int)\n",
    "\n",
    "print(\"T1 Macro-F1 (TRAIN) XLMR:   \", macro_f1(y_train_t1, pred_x_train_t1))\n",
    "print(\"T1 Macro-F1 (TRAIN) DeBERTa:\", macro_f1(y_train_t1, pred_d_train_t1))\n",
    "print(\"T1 Macro-F1 (TRAIN) ENS:    \", macro_f1(y_train_t1, pred_ens_train_t1))\n",
    "\n",
    "# 2.4 DEV: load cached probs, ensemble, write submission\n",
    "t1_dev_x = pd.read_csv(XLMR_CACHE_ROOT / \"t1_dev_probs.csv\")   # id, prob_pos\n",
    "t1_dev_d = pd.read_csv(DEBERTA_CACHE_ROOT / \"t1_dev_probs.csv\")\n",
    "\n",
    "t1_dev = t1_dev_x.merge(\n",
    "    t1_dev_d, on=\"id\", suffixes=(\"_xlmr\", \"_deberta\")\n",
    ")\n",
    "print(\"T1 dev merged shape:\", t1_dev.shape)\n",
    "\n",
    "p_x_dev_t1 = t1_dev[\"prob_pos_xlmr\"].values\n",
    "p_d_dev_t1 = t1_dev[\"prob_pos_deberta\"].values\n",
    "p_ens_dev_t1 = 0.5 * (p_x_dev_t1 + p_d_dev_t1)\n",
    "\n",
    "pred_ens_dev_t1 = (p_ens_dev_t1 >= thr_ens_t1).astype(int)\n",
    "\n",
    "sub1 = pd.DataFrame({\n",
    "    \"id\": t1_dev[\"id\"].astype(str),\n",
    "    \"polarization\": pred_ens_dev_t1.astype(int),\n",
    "})\n",
    "sub1_path = SUB_ROOT_ENS / \"subtask_1\" / f\"pred_{lang_fname}.csv\"\n",
    "sub1.to_csv(sub1_path, index=False)\n",
    "print(\"Subtask 1 ensemble submission written to:\", sub1_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db46aa4d",
   "metadata": {},
   "source": [
    "## Subtask 2 — Type classification (multi-label: 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b8d581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Subtask 2 (type multi-label) ====================\n",
      "T2 train merged shape: (3222, 21)\n",
      "T2 thresholds XLMR: {'gender/sexual': 0.85, 'political': 0.35, 'religious': 0.95, 'racial/ethnic': 0.9, 'other': 0.7}\n",
      "T2 thresholds DeBERTa: {'gender/sexual': 0.7999999999999999, 'political': 0.49999999999999994, 'religious': 0.9, 'racial/ethnic': 0.65, 'other': 0.75}\n",
      "T2 thresholds ENS (avg): {'gender/sexual': 0.825, 'political': 0.42499999999999993, 'religious': 0.925, 'racial/ethnic': 0.775, 'other': 0.725}\n",
      "T2 Macro-F1 (TRAIN) XLMR:    0.4713820066883467\n",
      "T2 Macro-F1 (TRAIN) DeBERTa: 0.5422365856535791\n",
      "T2 Macro-F1 (TRAIN) ENS:     0.5478476095333539\n",
      "T2 dev merged shape: (160, 11)\n",
      "Subtask 2 ensemble submission written to: submissions/ensemble/subtask_2/pred_eng.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3) Subtask 2 — Type classification (multi-label: 5)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n==================== Subtask 2 (type multi-label) ====================\")\n",
    "\n",
    "# 3.1 TRAIN: load cached calibrated probs\n",
    "t2_train_x = pd.read_csv(XLMR_CACHE_ROOT / \"t2_train_probs.csv\")\n",
    "t2_train_d = pd.read_csv(DEBERTA_CACHE_ROOT / \"t2_train_probs.csv\")\n",
    "\n",
    "t2_train = t2_train_x.merge(\n",
    "    t2_train_d, on=\"id\", suffixes=(\"_xlmr\", \"_deberta\")\n",
    ")\n",
    "print(\"T2 train merged shape:\", t2_train.shape)\n",
    "\n",
    "# true labels (take from xlmr side)\n",
    "Y2_true_train = t2_train[[f\"label_{lab}_xlmr\" for lab in T2_LABELS]].values.astype(int)\n",
    "\n",
    "# model probabilities\n",
    "P2_x_train = np.stack(\n",
    "    [t2_train[f\"prob_{lab}_xlmr\"].values for lab in T2_LABELS],\n",
    "    axis=1,\n",
    ")\n",
    "P2_d_train = np.stack(\n",
    "    [t2_train[f\"prob_{lab}_deberta\"].values for lab in T2_LABELS],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# 3.2 Load per-model calibration thresholds\n",
    "cal_x_t2 = load_json(XLMR_ART_ROOT / \"calib_t2_native.json\")\n",
    "cal_d_t2 = load_json(DEBERTA_ART_ROOT / \"calib_t2_native.json\")\n",
    "\n",
    "thr_x_map_t2 = {lab: float(cal_x_t2[\"thresholds\"][lab]) for lab in T2_LABELS}\n",
    "thr_d_map_t2 = {lab: float(cal_d_t2[\"thresholds\"][lab]) for lab in T2_LABELS}\n",
    "thr_ens_map_t2 = {\n",
    "    lab: 0.5 * (thr_x_map_t2[lab] + thr_d_map_t2[lab]) for lab in T2_LABELS\n",
    "}\n",
    "\n",
    "print(\"T2 thresholds XLMR:\", thr_x_map_t2)\n",
    "print(\"T2 thresholds DeBERTa:\", thr_d_map_t2)\n",
    "print(\"T2 thresholds ENS (avg):\", thr_ens_map_t2)\n",
    "\n",
    "# 3.3 TRAIN F1: XLMR, DeBERTa, Ensemble\n",
    "P2_x_pred = np.zeros_like(P2_x_train, dtype=int)\n",
    "P2_d_pred = np.zeros_like(P2_d_train, dtype=int)\n",
    "P2_ens_pred = np.zeros_like(P2_x_train, dtype=int)\n",
    "\n",
    "for j, lab in enumerate(T2_LABELS):\n",
    "    thrx = thr_x_map_t2[lab]\n",
    "    thrd = thr_d_map_t2[lab]\n",
    "    thrE = thr_ens_map_t2[lab]\n",
    "    P2_x_pred[:, j]   = (P2_x_train[:, j] >= thrx).astype(int)\n",
    "    P2_d_pred[:, j]   = (P2_d_train[:, j] >= thrd).astype(int)\n",
    "    P2_ens_pred[:, j] = ((0.5*(P2_x_train[:, j] + P2_d_train[:, j])) >= thrE).astype(int)\n",
    "\n",
    "print(\"T2 Macro-F1 (TRAIN) XLMR:   \", macro_f1(Y2_true_train, P2_x_pred))\n",
    "print(\"T2 Macro-F1 (TRAIN) DeBERTa:\", macro_f1(Y2_true_train, P2_d_pred))\n",
    "print(\"T2 Macro-F1 (TRAIN) ENS:    \", macro_f1(Y2_true_train, P2_ens_pred))\n",
    "\n",
    "# 3.4 DEV: load cached probs, ensemble, submission\n",
    "t2_dev_x = pd.read_csv(XLMR_CACHE_ROOT / \"t2_dev_probs.csv\")\n",
    "t2_dev_d = pd.read_csv(DEBERTA_CACHE_ROOT / \"t2_dev_probs.csv\")\n",
    "\n",
    "t2_dev = t2_dev_x.merge(\n",
    "    t2_dev_d, on=\"id\", suffixes=(\"_xlmr\", \"_deberta\")\n",
    ")\n",
    "print(\"T2 dev merged shape:\", t2_dev.shape)\n",
    "\n",
    "P2_x_dev = np.stack(\n",
    "    [t2_dev[f\"prob_{lab}_xlmr\"].values for lab in T2_LABELS],\n",
    "    axis=1,\n",
    ")\n",
    "P2_d_dev = np.stack(\n",
    "    [t2_dev[f\"prob_{lab}_deberta\"].values for lab in T2_LABELS],\n",
    "    axis=1,\n",
    ")\n",
    "P2_ens_dev = 0.5 * (P2_x_dev + P2_d_dev)\n",
    "\n",
    "P2_ens_pred_dev = np.zeros_like(P2_ens_dev, dtype=int)\n",
    "for j, lab in enumerate(T2_LABELS):\n",
    "    thrE = thr_ens_map_t2[lab]\n",
    "    P2_ens_pred_dev[:, j] = (P2_ens_dev[:, j] >= thrE).astype(int)\n",
    "\n",
    "# Build submission in Codabench column order:\n",
    "# id,political,racial/ethnic,religious,gender/sexual,other\n",
    "idx2 = {lab: i for i, lab in enumerate(T2_LABELS)}\n",
    "\n",
    "sub2 = pd.DataFrame({\n",
    "    \"id\": t2_dev[\"id\"].astype(str),\n",
    "    \"political\":      P2_ens_pred_dev[:, idx2[\"political\"]],\n",
    "    \"racial/ethnic\":  P2_ens_pred_dev[:, idx2[\"racial/ethnic\"]],\n",
    "    \"religious\":      P2_ens_pred_dev[:, idx2[\"religious\"]],\n",
    "    \"gender/sexual\":  P2_ens_pred_dev[:, idx2[\"gender/sexual\"]],\n",
    "    \"other\":          P2_ens_pred_dev[:, idx2[\"other\"]],\n",
    "})\n",
    "sub2_path = SUB_ROOT_ENS / \"subtask_2\" / f\"pred_{lang_fname}.csv\"\n",
    "sub2.to_csv(sub2_path, index=False)\n",
    "print(\"Subtask 2 ensemble submission written to:\", sub2_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52b1144",
   "metadata": {},
   "source": [
    "## Subtask 3 — Manifestation (multi-label: 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c04f1245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Subtask 3 (manifestation) ====================\n",
      "T3 train merged shape: (3222, 25)\n",
      "T3 thresholds XLMR: {'vilification': 0.65, 'extreme_language': 0.6, 'stereotype': 0.7, 'invalidation': 0.65, 'lack_of_empathy': 0.65, 'dehumanization': 0.7}\n",
      "T3 thresholds DeBERTa: {'vilification': 0.44999999999999996, 'extreme_language': 0.65, 'stereotype': 0.75, 'invalidation': 0.49999999999999994, 'lack_of_empathy': 0.65, 'dehumanization': 0.7}\n",
      "T3 thresholds ENS (avg): {'vilification': 0.55, 'extreme_language': 0.625, 'stereotype': 0.725, 'invalidation': 0.575, 'lack_of_empathy': 0.65, 'dehumanization': 0.7}\n",
      "T3 Macro-F1 (TRAIN) XLMR:    0.5175818625510322\n",
      "T3 Macro-F1 (TRAIN) DeBERTa: 0.6336362476490647\n",
      "T3 Macro-F1 (TRAIN) ENS:     0.614528150933099\n",
      "T3 dev merged shape: (160, 13)\n",
      "Subtask 3 ensemble submission written to: submissions/ensemble/subtask_3/pred_eng.csv\n",
      "\n",
      "All ensemble submissions ready.\n",
      "Zip one of these folders for Codabench:\n",
      "   submissions/ensemble/subtask_1\n",
      "   submissions/ensemble/subtask_2\n",
      "   submissions/ensemble/subtask_3\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4) Subtask 3 — Manifestation (multi-label: 6)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n==================== Subtask 3 (manifestation) ====================\")\n",
    "\n",
    "# 4.1 TRAIN: load cached calibrated probs\n",
    "t3_train_x = pd.read_csv(XLMR_CACHE_ROOT / \"t3_train_probs.csv\")\n",
    "t3_train_d = pd.read_csv(DEBERTA_CACHE_ROOT / \"t3_train_probs.csv\")\n",
    "\n",
    "t3_train = t3_train_x.merge(\n",
    "    t3_train_d, on=\"id\", suffixes=(\"_xlmr\", \"_deberta\")\n",
    ")\n",
    "print(\"T3 train merged shape:\", t3_train.shape)\n",
    "\n",
    "Y3_true_train = t3_train[[f\"label_{lab}_xlmr\" for lab in T3_LABELS]].values.astype(int)\n",
    "\n",
    "P3_x_train = np.stack(\n",
    "    [t3_train[f\"prob_{lab}_xlmr\"].values for lab in T3_LABELS],\n",
    "    axis=1,\n",
    ")\n",
    "P3_d_train = np.stack(\n",
    "    [t3_train[f\"prob_{lab}_deberta\"].values for lab in T3_LABELS],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# 4.2 Load per-model calibration thresholds\n",
    "cal_x_t3 = load_json(XLMR_ART_ROOT / \"calib_t3_native.json\")\n",
    "cal_d_t3 = load_json(DEBERTA_ART_ROOT / \"calib_t3_native.json\")\n",
    "\n",
    "thr_x_map_t3 = {lab: float(cal_x_t3[\"thresholds\"][lab]) for lab in T3_LABELS}\n",
    "thr_d_map_t3 = {lab: float(cal_d_t3[\"thresholds\"][lab]) for lab in T3_LABELS}\n",
    "thr_ens_map_t3 = {\n",
    "    lab: 0.5 * (thr_x_map_t3[lab] + thr_d_map_t3[lab]) for lab in T3_LABELS\n",
    "}\n",
    "\n",
    "print(\"T3 thresholds XLMR:\", thr_x_map_t3)\n",
    "print(\"T3 thresholds DeBERTa:\", thr_d_map_t3)\n",
    "print(\"T3 thresholds ENS (avg):\", thr_ens_map_t3)\n",
    "\n",
    "# 4.3 TRAIN F1: XLMR, DeBERTa, ENS\n",
    "P3_x_pred = np.zeros_like(P3_x_train, dtype=int)\n",
    "P3_d_pred = np.zeros_like(P3_d_train, dtype=int)\n",
    "P3_ens_pred = np.zeros_like(P3_x_train, dtype=int)\n",
    "\n",
    "for j, lab in enumerate(T3_LABELS):\n",
    "    thrx = thr_x_map_t3[lab]\n",
    "    thrd = thr_d_map_t3[lab]\n",
    "    thrE = thr_ens_map_t3[lab]\n",
    "    P3_x_pred[:, j]   = (P3_x_train[:, j] >= thrx).astype(int)\n",
    "    P3_d_pred[:, j]   = (P3_d_train[:, j] >= thrd).astype(int)\n",
    "    P3_ens_pred[:, j] = ((0.5*(P3_x_train[:, j] + P3_d_train[:, j])) >= thrE).astype(int)\n",
    "\n",
    "print(\"T3 Macro-F1 (TRAIN) XLMR:   \", macro_f1(Y3_true_train, P3_x_pred))\n",
    "print(\"T3 Macro-F1 (TRAIN) DeBERTa:\", macro_f1(Y3_true_train, P3_d_pred))\n",
    "print(\"T3 Macro-F1 (TRAIN) ENS:    \", macro_f1(Y3_true_train, P3_ens_pred))\n",
    "\n",
    "# 4.4 DEV: load cached probs, ensemble, submission\n",
    "t3_dev_x = pd.read_csv(XLMR_CACHE_ROOT / \"t3_dev_probs.csv\")\n",
    "t3_dev_d = pd.read_csv(DEBERTA_CACHE_ROOT / \"t3_dev_probs.csv\")\n",
    "\n",
    "t3_dev = t3_dev_x.merge(\n",
    "    t3_dev_d, on=\"id\", suffixes=(\"_xlmr\", \"_deberta\")\n",
    ")\n",
    "print(\"T3 dev merged shape:\", t3_dev.shape)\n",
    "\n",
    "P3_x_dev = np.stack(\n",
    "    [t3_dev[f\"prob_{lab}_xlmr\"].values for lab in T3_LABELS],\n",
    "    axis=1,\n",
    ")\n",
    "P3_d_dev = np.stack(\n",
    "    [t3_dev[f\"prob_{lab}_deberta\"].values for lab in T3_LABELS],\n",
    "    axis=1,\n",
    ")\n",
    "P3_ens_dev = 0.5 * (P3_x_dev + P3_d_dev)\n",
    "\n",
    "P3_ens_pred_dev = np.zeros_like(P3_ens_dev, dtype=int)\n",
    "for j, lab in enumerate(T3_LABELS):\n",
    "    thrE = thr_ens_map_t3[lab]\n",
    "    P3_ens_pred_dev[:, j] = (P3_ens_dev[:, j] >= thrE).astype(int)\n",
    "\n",
    "# Build submission in Codabench order:\n",
    "# id,stereotype,vilification,dehumanization,extreme_language,lack_of_empathy,invalidation\n",
    "idx3 = {lab: i for i, lab in enumerate(T3_LABELS)}\n",
    "\n",
    "sub3 = pd.DataFrame({\n",
    "    \"id\": t3_dev[\"id\"].astype(str),\n",
    "    \"stereotype\":       P3_ens_pred_dev[:, idx3[\"stereotype\"]],\n",
    "    \"vilification\":     P3_ens_pred_dev[:, idx3[\"vilification\"]],\n",
    "    \"dehumanization\":   P3_ens_pred_dev[:, idx3[\"dehumanization\"]],\n",
    "    \"extreme_language\": P3_ens_pred_dev[:, idx3[\"extreme_language\"]],\n",
    "    \"lack_of_empathy\":  P3_ens_pred_dev[:, idx3[\"lack_of_empathy\"]],\n",
    "    \"invalidation\":     P3_ens_pred_dev[:, idx3[\"invalidation\"]],\n",
    "})\n",
    "sub3_path = SUB_ROOT_ENS / \"subtask_3\" / f\"pred_{lang_fname}.csv\"\n",
    "sub3.to_csv(sub3_path, index=False)\n",
    "print(\"Subtask 3 ensemble submission written to:\", sub3_path)\n",
    "\n",
    "print(\"\\nAll ensemble submissions ready.\")\n",
    "print(\"Zip one of these folders for Codabench:\")\n",
    "print(\"  \", SUB_ROOT_ENS / \"subtask_1\")\n",
    "print(\"  \", SUB_ROOT_ENS / \"subtask_2\")\n",
    "print(\"  \", SUB_ROOT_ENS / \"subtask_3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
