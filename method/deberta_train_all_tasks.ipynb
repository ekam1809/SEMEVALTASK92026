{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f27a7113",
   "metadata": {},
   "source": [
    "## SETUP: environment, device toggle, imports, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b765c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 18:20:08.368782: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-07 18:20:08.382058: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765160408.395546 3937706 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765160408.399602 3937706 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1765160408.412173 3937706 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765160408.412189 3937706 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765160408.412190 3937706 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765160408.412192 3937706 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-12-07 18:20:08.416858: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.0\n",
      "Transformers: 4.57.1\n",
      "Using GPU: NVIDIA H100 80GB HBM3 MIG 2g.20gb\n",
      "LANG=eng, MODEL=microsoft/deberta-v3-base, EPOCHS=3, LR=2e-05, BATCH_TRAIN=8\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0) SETUP: environment, device toggle, imports, config\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"   # avoid TF / tf_keras imports\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import random\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    pipeline,\n",
    ")\n",
    "import transformers\n",
    "\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"Transformers:\", transformers.__version__)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Device selection: switch between GPU / CPU here\n",
    "# ------------------------------------------------------------\n",
    "RUN_DEVICE = \"gpu\"  # \"gpu\" or \"cpu\"\n",
    "\n",
    "if RUN_DEVICE.lower() == \"gpu\" and torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.set_num_threads(max(1, os.cpu_count() // 2))\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Reproducibility\n",
    "# ------------------------------------------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if DEVICE.type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# High-level config\n",
    "# ------------------------------------------------------------\n",
    "LANG = \"eng\"                          # e.g. \"eng\", \"ben\", \"hin\", etc.\n",
    "BASE = \"../dev_phase\"                 # root of organizer data\n",
    "EN_MODEL = \"microsoft/deberta-v3-base\"\n",
    "\n",
    "MAX_LEN = 192\n",
    "EPOCHS = 3\n",
    "LR = 2e-5\n",
    "BATCH_TRAIN_GPU = 8\n",
    "BATCH_TRAIN_CPU = 4\n",
    "BATCH_EVAL = 8\n",
    "BATCH_TRAIN = BATCH_TRAIN_GPU if DEVICE.type == \"cuda\" else BATCH_TRAIN_CPU\n",
    "WEIGHT_DECAY = 0.01\n",
    "WARMUP_RATIO = 0.1\n",
    "GRAD_ACCUM = 1  \n",
    "\n",
    "print(f\"LANG={LANG}, MODEL={EN_MODEL}, EPOCHS={EPOCHS}, LR={LR}, BATCH_TRAIN={BATCH_TRAIN}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Paths / dirs\n",
    "# ------------------------------------------------------------\n",
    "lang_fname = LANG  # if your filenames differ, adjust here\n",
    "\n",
    "# TRAIN + DEV (DEV is UNLABELED in this setup)\n",
    "T1_TRAIN = f\"{BASE}/subtask1/train/{lang_fname}.csv\"\n",
    "T1_DEV   = f\"{BASE}/subtask1/dev/{lang_fname}.csv\"\n",
    "\n",
    "T2_TRAIN = f\"{BASE}/subtask2/train/{lang_fname}.csv\"\n",
    "T2_DEV   = f\"{BASE}/subtask2/dev/{lang_fname}.csv\"\n",
    "\n",
    "T3_TRAIN = f\"{BASE}/subtask3/train/{lang_fname}.csv\"\n",
    "T3_DEV   = f\"{BASE}/subtask3/dev/{lang_fname}.csv\"\n",
    "\n",
    "# method-specific roots\n",
    "ART_ROOT   = Path(\"artifacts\") / \"deberta\" / LANG\n",
    "CACHE_ROOT = Path(\"cache\") / \"deberta\" / LANG\n",
    "OUT_ROOT   = Path(\"outputs\") / \"deberta\" / LANG\n",
    "SUB_ROOT   = Path(\"submissions\") / \"deberta\"\n",
    "\n",
    "for d in [ART_ROOT, CACHE_ROOT, OUT_ROOT, SUB_ROOT]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Submission subfolders\n",
    "(SUB_ROOT / \"subtask_1\").mkdir(parents=True, exist_ok=True)\n",
    "(SUB_ROOT / \"subtask_2\").mkdir(parents=True, exist_ok=True)\n",
    "(SUB_ROOT / \"subtask_3\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "T2_LABELS = [\"gender/sexual\", \"political\", \"religious\", \"racial/ethnic\", \"other\"]\n",
    "T3_LABELS = [\"vilification\", \"extreme_language\", \"stereotype\",\n",
    "             \"invalidation\", \"lack_of_empathy\", \"dehumanization\"]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# TrainingArguments capability detection\n",
    "# ------------------------------------------------------------\n",
    "import inspect\n",
    "_TA_PARAMS = inspect.signature(TrainingArguments.__init__).parameters\n",
    "TRAINER_CAPS = {\n",
    "    \"evaluation_strategy\": \"evaluation_strategy\" in _TA_PARAMS,\n",
    "    \"save_strategy\":       \"save_strategy\" in _TA_PARAMS,\n",
    "    \"warmup_ratio\":        \"warmup_ratio\" in _TA_PARAMS,\n",
    "    \"fp16\":                \"fp16\" in _TA_PARAMS,\n",
    "    \"no_cuda\":             \"no_cuda\" in _TA_PARAMS,\n",
    "    \"use_mps_device\":      \"use_mps_device\" in _TA_PARAMS,\n",
    "    \"report_to\":           \"report_to\" in _TA_PARAMS,\n",
    "    \"grad_accum\":          \"gradient_accumulation_steps\" in _TA_PARAMS,\n",
    "    \"eval_accum\":          \"eval_accumulation_steps\" in _TA_PARAMS,\n",
    "}\n",
    "\n",
    "def build_training_args(\n",
    "    output_dir,\n",
    "    per_device_train_batch_size,\n",
    "    per_device_eval_batch_size,\n",
    "    num_train_epochs,\n",
    "    learning_rate,\n",
    "    weight_decay,\n",
    "    logging_steps=50,\n",
    "    evaluation=\"epoch\",\n",
    "    save=\"no\",\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    warmup_steps=0,\n",
    "):\n",
    "    use_cuda_flag = (DEVICE.type == \"cuda\")\n",
    "    kwargs = dict(\n",
    "        output_dir=str(output_dir),\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        logging_steps=logging_steps,\n",
    "        dataloader_pin_memory=use_cuda_flag,\n",
    "        dataloader_num_workers=0,\n",
    "    )\n",
    "    if TRAINER_CAPS[\"evaluation_strategy\"]:\n",
    "        kwargs[\"evaluation_strategy\"] = evaluation\n",
    "    if TRAINER_CAPS[\"save_strategy\"]:\n",
    "        kwargs[\"save_strategy\"] = save\n",
    "    if TRAINER_CAPS[\"warmup_ratio\"]:\n",
    "        kwargs[\"warmup_ratio\"] = warmup_ratio\n",
    "    else:\n",
    "        kwargs[\"warmup_steps\"] = warmup_steps\n",
    "    if TRAINER_CAPS[\"fp16\"]:\n",
    "        kwargs[\"fp16\"] = False\n",
    "    if TRAINER_CAPS[\"no_cuda\"]:\n",
    "        kwargs[\"no_cuda\"] = not use_cuda_flag\n",
    "    if TRAINER_CAPS[\"use_mps_device\"]:\n",
    "        kwargs[\"use_mps_device\"] = False\n",
    "    if TRAINER_CAPS[\"report_to\"]:\n",
    "        kwargs[\"report_to\"] = \"none\"\n",
    "    if TRAINER_CAPS[\"grad_accum\"]:\n",
    "        kwargs[\"gradient_accumulation_steps\"] = GRAD_ACCUM\n",
    "    if TRAINER_CAPS[\"eval_accum\"]:\n",
    "        kwargs[\"eval_accumulation_steps\"] = 4\n",
    "    return TrainingArguments(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601ea82e",
   "metadata": {},
   "source": [
    "## DATASET + METRICS + CALIBRATION HELPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a03a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) DATASET + METRICS + CALIBRATION HELPERS\n",
    "# ============================================================\n",
    "\n",
    "class TextClsDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: List[str],\n",
    "        labels: Optional[List] = None,\n",
    "        tokenizer=None,\n",
    "        max_len: int = 256,\n",
    "        is_multilabel: bool = False,\n",
    "    ):\n",
    "        self.texts = list(texts)\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.is_multilabel = is_multilabel\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        text = str(self.texts[idx])\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=False,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        if self.labels is not None:\n",
    "            y = self.labels[idx]\n",
    "            item[\"labels\"] = torch.tensor(\n",
    "                y,\n",
    "                dtype=torch.float if self.is_multilabel else torch.long,\n",
    "            )\n",
    "        return item\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "def grid_search_thresholds(y_true, y_prob, label_names=None):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    C = y_true.shape[1]\n",
    "    grid = np.linspace(0.05, 0.95, 19)\n",
    "    thrs = {}\n",
    "    for c in range(C):\n",
    "        best_t, best_f = 0.5, -1.0\n",
    "        for t in grid:\n",
    "            preds = (y_prob[:, c] >= t).astype(int)\n",
    "            f = f1_score(y_true[:, c], preds, average=\"binary\", zero_division=0)\n",
    "            if f > best_f:\n",
    "                best_f, best_t = f, t\n",
    "        name = label_names[c] if label_names else str(c)\n",
    "        thrs[name] = float(best_t)\n",
    "    return thrs\n",
    "\n",
    "class TempScaler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.T = nn.Parameter(torch.ones(1))\n",
    "\n",
    "    def forward(self, logits):\n",
    "        return logits / self.T\n",
    "\n",
    "def learn_temperature(dev_logits, dev_labels, is_multilabel: bool):\n",
    "    \"\"\"\n",
    "    Simple temperature scaling on CPU.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cpu\")\n",
    "    scaler = TempScaler().to(device)\n",
    "    dev_logits = dev_logits.to(device)\n",
    "    dev_labels = dev_labels.to(device)\n",
    "\n",
    "    opt = torch.optim.LBFGS([scaler.T], max_iter=50)\n",
    "    criterion = nn.BCEWithLogitsLoss() if is_multilabel else nn.CrossEntropyLoss()\n",
    "\n",
    "    def closure():\n",
    "        opt.zero_grad()\n",
    "        z = scaler(dev_logits)\n",
    "        loss = criterion(\n",
    "            z,\n",
    "            dev_labels.float() if is_multilabel else dev_labels.long(),\n",
    "        )\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    opt.step(closure)\n",
    "    return float(scaler.T.detach().cpu().item())\n",
    "\n",
    "def collect_logits(trainer: Trainer, dataset: Dataset, is_multilabel: bool):\n",
    "    preds = trainer.predict(dataset)\n",
    "    raw = preds.predictions\n",
    "    if isinstance(raw, (list, tuple)):\n",
    "        raw = raw[0]\n",
    "    logits = torch.tensor(raw)\n",
    "    labels = torch.tensor(preds.label_ids)\n",
    "    if not is_multilabel and logits.ndim == 1:\n",
    "        logits = logits.unsqueeze(1)\n",
    "    return logits, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2bbdcb",
   "metadata": {},
   "source": [
    "## TRANSLATION HELPERS (for non-ENG), text_en caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8591c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2) TRANSLATION HELPERS (for non-ENG), text_en caching\n",
    "# ============================================================\n",
    "\n",
    "def _opus_model_for_lang(lang: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Map language code -> OPUS-MT model name (to EN).\n",
    "    Extend as needed for your languages.\n",
    "    \"\"\"\n",
    "    lang = lang.lower()\n",
    "    if lang in {\"bn\", \"ben\"}:\n",
    "        return \"Helsinki-NLP/opus-mt-bn-en\"\n",
    "    if lang in {\"pa\", \"pan\"}:\n",
    "        return \"Helsinki-NLP/opus-mt-pa-en\"\n",
    "    if lang in {\"hi\", \"hin\"}:\n",
    "        return \"Helsinki-NLP/opus-mt-hi-en\"\n",
    "    return None\n",
    "\n",
    "def translate_series_to_en(texts, model_name: str, batch_size: int = 16, max_len: int = 256):\n",
    "    if model_name is None:\n",
    "        return [str(t) for t in texts]\n",
    "\n",
    "    tok = AutoTokenizer.from_pretrained(model_name)\n",
    "    mt  = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    if DEVICE.type == \"cuda\":\n",
    "        mt.to(DEVICE)\n",
    "        pipe = pipeline(\"translation\", model=mt, tokenizer=tok, device=0)  # GPU 0\n",
    "    else:\n",
    "        mt.to(torch.device(\"cpu\"))\n",
    "        pipe = pipeline(\"translation\", model=mt, tokenizer=tok, device=-1)  # CPU\n",
    "\n",
    "    out = []\n",
    "    batch = []\n",
    "    for t in texts:\n",
    "        batch.append(\"\" if not isinstance(t, str) else t)\n",
    "        if len(batch) == batch_size:\n",
    "            res = pipe(batch, max_length=max_len)\n",
    "            out.extend([r[\"translation_text\"] for r in res])\n",
    "            batch = []\n",
    "    if batch:\n",
    "        res = pipe(batch, max_length=max_len)\n",
    "        out.extend([r[\"translation_text\"] for r in res])\n",
    "    return out\n",
    "\n",
    "def ensure_text_en(df: pd.DataFrame, subtask_tag: str, lang: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds `text_en` to df.\n",
    "    - If LANG == \"eng\": just copy `text` -> `text_en`.\n",
    "    - Else: translate (and cache) in CACHE_ROOT / f\"t{subtask_tag}__{lang}__to_en.csv\".\n",
    "    Cache format: at least columns ['id','text_en'] if 'id' exists, else just 'text_en'.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    lang = lang.lower()\n",
    "\n",
    "    if lang == \"eng\":\n",
    "        df[\"text_en\"] = df[\"text\"].astype(str)\n",
    "        return df\n",
    "\n",
    "    cache_path = CACHE_ROOT / f\"t{subtask_tag}__{lang}__to_en.csv\"\n",
    "    if cache_path.exists():\n",
    "        cache = pd.read_csv(cache_path)\n",
    "        if \"id\" in df.columns and \"id\" in cache.columns:\n",
    "            df = df.merge(cache[[\"id\", \"text_en\"]], on=\"id\", how=\"left\")\n",
    "        else:\n",
    "            df[\"text_en\"] = cache[\"text_en\"]\n",
    "        need = df[\"text_en\"].isna() | (df[\"text_en\"].astype(str).str.len() == 0)\n",
    "        if need.any():\n",
    "            model_name = _opus_model_for_lang(lang)\n",
    "            df.loc[need, \"text_en\"] = translate_series_to_en(\n",
    "                df.loc[need, \"text\"], model_name\n",
    "            )\n",
    "            # refresh cache\n",
    "            if \"id\" in df.columns:\n",
    "                to_save = df[[\"id\", \"text_en\"]]\n",
    "            else:\n",
    "                to_save = pd.DataFrame({\"text_en\": df[\"text_en\"]})\n",
    "            to_save.to_csv(cache_path, index=False)\n",
    "        return df\n",
    "\n",
    "    # No cache yet → translate all\n",
    "    model_name = _opus_model_for_lang(lang)\n",
    "    df[\"text_en\"] = translate_series_to_en(df[\"text\"], model_name)\n",
    "    if \"id\" in df.columns:\n",
    "        to_save = df[[\"id\", \"text_en\"]]\n",
    "    else:\n",
    "        to_save = pd.DataFrame({\"text_en\": df[\"text_en\"]})\n",
    "    to_save.to_csv(cache_path, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad362e5e",
   "metadata": {},
   "source": [
    "## SUBTASK 1 — Polarization detection (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08935847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtask 1 (DeBERTa) trainer device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1209' max='1209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1209/1209 01:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.702500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.616900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.540400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.510400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.540500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.445500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.448200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.346600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.380700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.391900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.360900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.372500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.346300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.360700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.353700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.240100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.202300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.265800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.175500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.235300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.298500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.314600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.203900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 Macro-F1 (TRAIN, 0.5 thr): 0.9540936933186643\n",
      "T1 calibration (TRAIN): T=1.4648, best_thr=0.35, macroF1=0.9553\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote Subtask 1 submission CSV: submissions/deberta/subtask_1/pred_eng.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3) SUBTASK 1 — Polarization detection (binary)\n",
    "#    Train+F1+calibrate on train, infer on dev, save cache + submission\n",
    "# ============================================================\n",
    "\n",
    "# 3.1 Load TRAIN + DEV\n",
    "t1_train_df = pd.read_csv(T1_TRAIN)\n",
    "t1_dev_df   = pd.read_csv(T1_DEV)\n",
    "\n",
    "required_train_cols_t1 = {\"id\", \"text\", \"polarization\"}\n",
    "required_dev_cols_t1   = {\"id\", \"text\"}\n",
    "assert required_train_cols_t1.issubset(t1_train_df.columns), f\"T1 TRAIN missing: {required_train_cols_t1 - set(t1_train_df.columns)}\"\n",
    "assert required_dev_cols_t1.issubset(t1_dev_df.columns),     f\"T1 DEV missing: {required_dev_cols_t1 - set(t1_dev_df.columns)}\"\n",
    "\n",
    "t1_train_df[\"polarization\"] = t1_train_df[\"polarization\"].astype(int)\n",
    "\n",
    "# 3.2 Build text_en for DeBERTa\n",
    "t1_train_df = ensure_text_en(t1_train_df, subtask_tag=\"1\", lang=LANG)\n",
    "t1_dev_df   = ensure_text_en(t1_dev_df,   subtask_tag=\"1\", lang=LANG)\n",
    "\n",
    "# 3.3 Model + tokenizer\n",
    "tok_t1 = AutoTokenizer.from_pretrained(EN_MODEL, use_fast=True)\n",
    "cfg_t1 = AutoConfig.from_pretrained(EN_MODEL, num_labels=2)\n",
    "mdl_t1 = AutoModelForSequenceClassification.from_pretrained(EN_MODEL, config=cfg_t1)\n",
    "mdl_t1.config.use_cache = False\n",
    "if hasattr(mdl_t1, \"gradient_checkpointing_disable\"):\n",
    "    mdl_t1.gradient_checkpointing_disable()\n",
    "mdl_t1.to(DEVICE)\n",
    "\n",
    "# 3.4 Datasets\n",
    "ds_t1_train = TextClsDataset(\n",
    "    texts=t1_train_df[\"text_en\"].tolist(),\n",
    "    labels=t1_train_df[\"polarization\"].tolist(),\n",
    "    tokenizer=tok_t1,\n",
    "    max_len=MAX_LEN,\n",
    "    is_multilabel=False,\n",
    ")\n",
    "# dev is unlabeled -> dummy zeros (not used for loss/metrics)\n",
    "ds_t1_dev = TextClsDataset(\n",
    "    texts=t1_dev_df[\"text_en\"].tolist(),\n",
    "    labels=[0] * len(t1_dev_df),\n",
    "    tokenizer=tok_t1,\n",
    "    max_len=MAX_LEN,\n",
    "    is_multilabel=False,\n",
    ")\n",
    "\n",
    "# 3.5 Trainer\n",
    "args_t1 = build_training_args(\n",
    "    output_dir=ART_ROOT / \"t1_tmp\",\n",
    "    per_device_train_batch_size=BATCH_TRAIN,\n",
    "    per_device_eval_batch_size=BATCH_EVAL,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    logging_steps=50,\n",
    "    evaluation=\"epoch\",\n",
    "    save=\"no\",\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    ")\n",
    "\n",
    "def compute_metrics_t1(eval_pred):\n",
    "    logits = eval_pred.predictions[0] if isinstance(eval_pred.predictions, (list, tuple)) else eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\"f1_macro\": macro_f1(labels, preds)}\n",
    "\n",
    "trainer_t1 = Trainer(\n",
    "    model=mdl_t1,\n",
    "    args=args_t1,\n",
    "    train_dataset=ds_t1_train,\n",
    "    eval_dataset=ds_t1_train,  # evaluate on TRAIN\n",
    "    tokenizer=tok_t1,\n",
    "    data_collator=DataCollatorWithPadding(tok_t1),\n",
    "    compute_metrics=compute_metrics_t1,\n",
    ")\n",
    "\n",
    "print(\"Subtask 1 (DeBERTa) trainer device:\", trainer_t1.args.device)\n",
    "\n",
    "# 3.6 Train + F1 on TRAIN (with 0.5 threshold implicit)\n",
    "trainer_t1.train()\n",
    "eval_t1_train_raw = trainer_t1.evaluate()\n",
    "print(\"T1 Macro-F1 (TRAIN, 0.5 thr):\", eval_t1_train_raw.get(\"eval_f1_macro\"))\n",
    "\n",
    "# 3.7 Calibrate (temperature + threshold) on TRAIN\n",
    "logits_t1_train, labels_t1_train = collect_logits(trainer_t1, ds_t1_train, is_multilabel=False)\n",
    "T_t1 = learn_temperature(logits_t1_train, labels_t1_train, is_multilabel=False)\n",
    "probs_t1_train = torch.softmax(logits_t1_train / T_t1, dim=1)[:, 1].cpu().numpy()\n",
    "\n",
    "best_thr_t1, best_f1_train = 0.5, -1.0\n",
    "for t in np.linspace(0.05, 0.95, 19):\n",
    "    pred = (probs_t1_train >= t).astype(int)\n",
    "    f = macro_f1(labels_t1_train.numpy(), pred)\n",
    "    if f > best_f1_train:\n",
    "        best_f1_train, best_thr_t1 = f, t\n",
    "\n",
    "print(f\"T1 calibration (TRAIN): T={T_t1:.4f}, best_thr={best_thr_t1:.2f}, macroF1={best_f1_train:.4f}\")\n",
    "\n",
    "# 3.8 Save model + calibration\n",
    "mdl_t1.save_pretrained(ART_ROOT / \"native_t1\")\n",
    "tok_t1.save_pretrained(ART_ROOT / \"native_t1\")\n",
    "with open(ART_ROOT / \"calib_t1_native.json\", \"w\") as f:\n",
    "    json.dump({\"temperature\": float(T_t1), \"threshold\": float(best_thr_t1)}, f, indent=2)\n",
    "\n",
    "# 3.9 Infer on DEV (unlabeled), cache probs, build submission CSV\n",
    "preds_dev_t1 = trainer_t1.predict(ds_t1_dev)\n",
    "logits_t1_dev = torch.tensor(preds_dev_t1.predictions if not isinstance(preds_dev_t1.predictions,(list,tuple)) else preds_dev_t1.predictions[0])\n",
    "probs_t1_dev = torch.softmax(logits_t1_dev / T_t1, dim=1)[:, 1].cpu().numpy()\n",
    "pred_t1_dev = (probs_t1_dev >= best_thr_t1).astype(int)\n",
    "\n",
    "# Cache for ensemble\n",
    "cache_t1_train = pd.DataFrame({\n",
    "    \"id\": t1_train_df[\"id\"].astype(str),\n",
    "    \"prob_pos\": probs_t1_train,\n",
    "    \"label\": t1_train_df[\"polarization\"].astype(int),\n",
    "})\n",
    "cache_t1_train.to_csv(CACHE_ROOT / \"t1_train_probs.csv\", index=False)\n",
    "\n",
    "cache_t1_dev = pd.DataFrame({\n",
    "    \"id\": t1_dev_df[\"id\"].astype(str),\n",
    "    \"prob_pos\": probs_t1_dev,\n",
    "})\n",
    "cache_t1_dev.to_csv(CACHE_ROOT / \"t1_dev_probs.csv\", index=False)\n",
    "\n",
    "# Submission CSV for subtask 1\n",
    "sub1 = pd.DataFrame({\n",
    "    \"id\": t1_dev_df[\"id\"].astype(str),\n",
    "    \"polarization\": pred_t1_dev.astype(int),\n",
    "})\n",
    "sub1_path = SUB_ROOT / \"subtask_1\" / f\"pred_{lang_fname}.csv\"\n",
    "sub1.to_csv(sub1_path, index=False)\n",
    "print(\"Wrote Subtask 1 submission CSV:\", sub1_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60e71de",
   "metadata": {},
   "source": [
    "## SUBTASK 2 — Type classification (multi-label: 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ca5ed83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtask 2 (DeBERTa) trainer device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1209' max='1209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1209/1209 01:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.218100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.279300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.169200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.414100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.380300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.376600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.459300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.416600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.118500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.839800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.262300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.090800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.937200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.042900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.894900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.772700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.794200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.763700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.970700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.977800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.666800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T2 Macro-F1 (TRAIN, thr=0.5): 0.48166939693340993\n",
      "T2 temperature: 1.1098158359527588\n",
      "T2 thresholds: {'gender/sexual': 0.7999999999999999, 'political': 0.49999999999999994, 'religious': 0.9, 'racial/ethnic': 0.65, 'other': 0.75}\n",
      "T2 Macro-F1 (TRAIN, calibrated): 0.5422365856535791\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote Subtask 2 submission CSV: submissions/deberta/subtask_2/pred_eng.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4) SUBTASK 2 — Type classification (multi-label: 5)\n",
    "# ============================================================\n",
    "\n",
    "# 4.1 Load TRAIN + DEV\n",
    "t2_train_df = pd.read_csv(T2_TRAIN)\n",
    "t2_dev_df   = pd.read_csv(T2_DEV)\n",
    "\n",
    "required_train_cols_t2 = {\"id\", \"text\", *T2_LABELS}\n",
    "required_dev_cols_t2   = {\"id\", \"text\"}\n",
    "assert required_train_cols_t2.issubset(t2_train_df.columns), f\"T2 TRAIN missing: {required_train_cols_t2 - set(t2_train_df.columns)}\"\n",
    "assert required_dev_cols_t2.issubset(t2_dev_df.columns),     f\"T2 DEV missing: {required_dev_cols_t2 - set(t2_dev_df.columns)}\"\n",
    "\n",
    "Y2_train = t2_train_df[T2_LABELS].values.astype(int)\n",
    "\n",
    "# 4.2 text_en\n",
    "t2_train_df = ensure_text_en(t2_train_df, subtask_tag=\"2\", lang=LANG)\n",
    "t2_dev_df   = ensure_text_en(t2_dev_df,   subtask_tag=\"2\", lang=LANG)\n",
    "\n",
    "# 4.3 Model + tokenizer\n",
    "tok_t2 = AutoTokenizer.from_pretrained(EN_MODEL, use_fast=True)\n",
    "cfg_t2 = AutoConfig.from_pretrained(\n",
    "    EN_MODEL,\n",
    "    num_labels=len(T2_LABELS),\n",
    "    problem_type=\"multi_label_classification\",\n",
    ")\n",
    "mdl_t2 = AutoModelForSequenceClassification.from_pretrained(EN_MODEL, config=cfg_t2)\n",
    "mdl_t2.config.use_cache = False\n",
    "if hasattr(mdl_t2, \"gradient_checkpointing_disable\"):\n",
    "    mdl_t2.gradient_checkpointing_disable()\n",
    "mdl_t2.to(DEVICE)\n",
    "\n",
    "# 4.4 Datasets\n",
    "ds_t2_train = TextClsDataset(\n",
    "    texts=t2_train_df[\"text_en\"].tolist(),\n",
    "    labels=Y2_train.tolist(),\n",
    "    tokenizer=tok_t2,\n",
    "    max_len=MAX_LEN,\n",
    "    is_multilabel=True,\n",
    ")\n",
    "ds_t2_dev = TextClsDataset(\n",
    "    texts=t2_dev_df[\"text_en\"].tolist(),\n",
    "    labels=[[0]*len(T2_LABELS)] * len(t2_dev_df),\n",
    "    tokenizer=tok_t2,\n",
    "    max_len=MAX_LEN,\n",
    "    is_multilabel=True,\n",
    ")\n",
    "\n",
    "# 4.5 Class imbalance (pos_weight)\n",
    "pos_count2 = Y2_train.sum(axis=0) + 1e-6\n",
    "neg_count2 = Y2_train.shape[0] - pos_count2\n",
    "pos_weight_2 = torch.tensor(neg_count2 / pos_count2, dtype=torch.float)\n",
    "\n",
    "class WeightedTrainerT2(Trainer):\n",
    "    def __init__(self, *args, pos_weight=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._pos_weight = pos_weight\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fn = nn.BCEWithLogitsLoss(pos_weight=self._pos_weight.to(logits.device))\n",
    "        loss = loss_fn(logits, labels.to(logits.device).float())\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "args_t2 = build_training_args(\n",
    "    output_dir=ART_ROOT / \"t2_tmp\",\n",
    "    per_device_train_batch_size=BATCH_TRAIN,\n",
    "    per_device_eval_batch_size=BATCH_EVAL,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    logging_steps=50,\n",
    "    evaluation=\"epoch\",\n",
    "    save=\"no\",\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    ")\n",
    "\n",
    "def compute_metrics_t2(eval_pred):\n",
    "    logits = eval_pred.predictions[0] if isinstance(eval_pred.predictions, (list, tuple)) else eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    return {\"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0)}\n",
    "\n",
    "trainer_t2 = WeightedTrainerT2(\n",
    "    model=mdl_t2,\n",
    "    args=args_t2,\n",
    "    train_dataset=ds_t2_train,\n",
    "    eval_dataset=ds_t2_train,  # evaluate on TRAIN\n",
    "    tokenizer=tok_t2,\n",
    "    data_collator=DataCollatorWithPadding(tok_t2),\n",
    "    compute_metrics=compute_metrics_t2,\n",
    "    pos_weight=pos_weight_2,\n",
    ")\n",
    "\n",
    "print(\"Subtask 2 (DeBERTa) trainer device:\", trainer_t2.args.device)\n",
    "\n",
    "# 4.6 Train + raw F1 (0.5 thr) on TRAIN\n",
    "trainer_t2.train()\n",
    "eval_t2_train_raw = trainer_t2.evaluate()\n",
    "print(\"T2 Macro-F1 (TRAIN, thr=0.5):\", eval_t2_train_raw.get(\"eval_f1_macro\"))\n",
    "\n",
    "# 4.7 Calibrate: temperature + label-wise thresholds on TRAIN\n",
    "logits_t2_train, labels_t2_train = collect_logits(trainer_t2, ds_t2_train, is_multilabel=True)\n",
    "T_t2 = learn_temperature(logits_t2_train, labels_t2_train, is_multilabel=True)\n",
    "probs_t2_train = torch.sigmoid(logits_t2_train / T_t2).cpu().numpy()\n",
    "thr_map_t2 = grid_search_thresholds(labels_t2_train.cpu().numpy(), probs_t2_train, T2_LABELS)\n",
    "\n",
    "# compute calibrated macro-F1 on TRAIN using those thresholds\n",
    "P2_train = np.zeros_like(probs_t2_train, dtype=int)\n",
    "for j, lab in enumerate(T2_LABELS):\n",
    "    P2_train[:, j] = (probs_t2_train[:, j] >= thr_map_t2[lab]).astype(int)\n",
    "f1_t2_cal = f1_score(labels_t2_train.cpu().numpy(), P2_train, average=\"macro\", zero_division=0)\n",
    "print(\"T2 temperature:\", T_t2)\n",
    "print(\"T2 thresholds:\", thr_map_t2)\n",
    "print(\"T2 Macro-F1 (TRAIN, calibrated):\", f1_t2_cal)\n",
    "\n",
    "# 4.8 Save model + calibration\n",
    "mdl_t2.save_pretrained(ART_ROOT / \"native_t2\")\n",
    "tok_t2.save_pretrained(ART_ROOT / \"native_t2\")\n",
    "with open(ART_ROOT / \"calib_t2_native.json\", \"w\") as f:\n",
    "    json.dump({\"temperature\": float(T_t2), \"thresholds\": thr_map_t2}, f, indent=2)\n",
    "\n",
    "# 4.9 Infer on DEV, cache probs, build submission CSV\n",
    "preds_dev_t2 = trainer_t2.predict(ds_t2_dev)\n",
    "logits_t2_dev = torch.tensor(preds_dev_t2.predictions if not isinstance(preds_dev_t2.predictions,(list,tuple)) else preds_dev_t2.predictions[0])\n",
    "probs_t2_dev = torch.sigmoid(logits_t2_dev / T_t2).cpu().numpy()\n",
    "\n",
    "P2_dev = np.zeros_like(probs_t2_dev, dtype=int)\n",
    "for j, lab in enumerate(T2_LABELS):\n",
    "    P2_dev[:, j] = (probs_t2_dev[:, j] >= thr_map_t2[lab]).astype(int)\n",
    "\n",
    "# Cache for ensemble\n",
    "train_cols = {\"id\": t2_train_df[\"id\"].astype(str)}\n",
    "for j, lab in enumerate(T2_LABELS):\n",
    "    train_cols[f\"prob_{lab}\"] = probs_t2_train[:, j]\n",
    "    train_cols[f\"label_{lab}\"] = labels_t2_train.cpu().numpy()[:, j]\n",
    "cache_t2_train = pd.DataFrame(train_cols)\n",
    "cache_t2_train.to_csv(CACHE_ROOT / \"t2_train_probs.csv\", index=False)\n",
    "\n",
    "dev_cols = {\"id\": t2_dev_df[\"id\"].astype(str)}\n",
    "for j, lab in enumerate(T2_LABELS):\n",
    "    dev_cols[f\"prob_{lab}\"] = probs_t2_dev[:, j]\n",
    "cache_t2_dev = pd.DataFrame(dev_cols)\n",
    "cache_t2_dev.to_csv(CACHE_ROOT / \"t2_dev_probs.csv\", index=False)\n",
    "\n",
    "# Submission CSV for subtask 2\n",
    "# Codabench header: id,political,racial/ethnic,religious,gender/sexual,other\n",
    "idx2 = {lab: i for i, lab in enumerate(T2_LABELS)}\n",
    "sub2 = pd.DataFrame({\n",
    "    \"id\": t2_dev_df[\"id\"].astype(str),\n",
    "    \"political\":      P2_dev[:, idx2[\"political\"]],\n",
    "    \"racial/ethnic\":  P2_dev[:, idx2[\"racial/ethnic\"]],\n",
    "    \"religious\":      P2_dev[:, idx2[\"religious\"]],\n",
    "    \"gender/sexual\":  P2_dev[:, idx2[\"gender/sexual\"]],\n",
    "    \"other\":          P2_dev[:, idx2[\"other\"]],\n",
    "})\n",
    "sub2_path = SUB_ROOT / \"subtask_2\" / f\"pred_{lang_fname}.csv\"\n",
    "sub2.to_csv(sub2_path, index=False)\n",
    "print(\"Wrote Subtask 2 submission CSV:\", sub2_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df097151",
   "metadata": {},
   "source": [
    "## SUBTASK 3 — Manifestation (multi-label: 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60009dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtask 3 (DeBERTa) trainer device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1209' max='1209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1209/1209 01:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.101100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.028700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.912300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.973300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.936100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.819900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.821900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.776900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.876100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.755200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.781600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.807300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.723000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.679900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.758600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.649700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.704800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.813700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.608700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T3 Macro-F1 (TRAIN, thr=0.5): 0.6129851481851645\n",
      "T3 temperature: 1.3111610412597656\n",
      "T3 thresholds: {'vilification': 0.44999999999999996, 'extreme_language': 0.65, 'stereotype': 0.75, 'invalidation': 0.49999999999999994, 'lack_of_empathy': 0.65, 'dehumanization': 0.7}\n",
      "T3 Macro-F1 (TRAIN, calibrated): 0.6336362476490647\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote Subtask 3 submission CSV: submissions/deberta/subtask_3/pred_eng.csv\n",
      "\n",
      "All DeBERTa training + calibration + dev submissions done.\n",
      "Submission roots (zip one subtask folder at a time for Codabench):\n",
      "   submissions/deberta/subtask_1\n",
      "   submissions/deberta/subtask_2\n",
      "   submissions/deberta/subtask_3\n",
      "Caches for ensembling live under: cache/deberta/eng\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5) SUBTASK 3 — Manifestation (multi-label: 6)\n",
    "# ============================================================\n",
    "\n",
    "# 5.1 Load TRAIN + DEV\n",
    "t3_train_df = pd.read_csv(T3_TRAIN)\n",
    "t3_dev_df   = pd.read_csv(T3_DEV)\n",
    "\n",
    "required_train_cols_t3 = {\"id\", \"text\", *T3_LABELS}\n",
    "required_dev_cols_t3   = {\"id\", \"text\"}\n",
    "assert required_train_cols_t3.issubset(t3_train_df.columns), f\"T3 TRAIN missing: {required_train_cols_t3 - set(t3_train_df.columns)}\"\n",
    "assert required_dev_cols_t3.issubset(t3_dev_df.columns),     f\"T3 DEV missing: {required_dev_cols_t3 - set(t3_dev_df.columns)}\"\n",
    "\n",
    "Y3_train = t3_train_df[T3_LABELS].values.astype(int)\n",
    "\n",
    "# 5.2 text_en\n",
    "t3_train_df = ensure_text_en(t3_train_df, subtask_tag=\"3\", lang=LANG)\n",
    "t3_dev_df   = ensure_text_en(t3_dev_df,   subtask_tag=\"3\", lang=LANG)\n",
    "\n",
    "# 5.3 Model + tokenizer\n",
    "tok_t3 = AutoTokenizer.from_pretrained(EN_MODEL, use_fast=True)\n",
    "cfg_t3 = AutoConfig.from_pretrained(\n",
    "    EN_MODEL,\n",
    "    num_labels=len(T3_LABELS),\n",
    "    problem_type=\"multi_label_classification\",\n",
    ")\n",
    "mdl_t3 = AutoModelForSequenceClassification.from_pretrained(EN_MODEL, config=cfg_t3)\n",
    "mdl_t3.config.use_cache = False\n",
    "if hasattr(mdl_t3, \"gradient_checkpointing_disable\"):\n",
    "    mdl_t3.gradient_checkpointing_disable()\n",
    "mdl_t3.to(DEVICE)\n",
    "\n",
    "# 5.4 Datasets\n",
    "ds_t3_train = TextClsDataset(\n",
    "    texts=t3_train_df[\"text_en\"].tolist(),\n",
    "    labels=Y3_train.tolist(),\n",
    "    tokenizer=tok_t3,\n",
    "    max_len=MAX_LEN,\n",
    "    is_multilabel=True,\n",
    ")\n",
    "ds_t3_dev = TextClsDataset(\n",
    "    texts=t3_dev_df[\"text_en\"].tolist(),\n",
    "    labels=[[0]*len(T3_LABELS)] * len(t3_dev_df),\n",
    "    tokenizer=tok_t3,\n",
    "    max_len=MAX_LEN,\n",
    "    is_multilabel=True,\n",
    ")\n",
    "\n",
    "# 5.5 Class imbalance (pos_weight)\n",
    "pos_count3 = Y3_train.sum(axis=0) + 1e-6\n",
    "neg_count3 = Y3_train.shape[0] - pos_count3\n",
    "pos_weight_3 = torch.tensor(neg_count3 / pos_count3, dtype=torch.float)\n",
    "\n",
    "class WeightedTrainerT3(Trainer):\n",
    "    def __init__(self, *args, pos_weight=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._pos_weight = pos_weight\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fn = nn.BCEWithLogitsLoss(pos_weight=self._pos_weight.to(logits.device))\n",
    "        loss = loss_fn(logits, labels.to(logits.device).float())\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "args_t3 = build_training_args(\n",
    "    output_dir=ART_ROOT / \"t3_tmp\",\n",
    "    per_device_train_batch_size=BATCH_TRAIN,\n",
    "    per_device_eval_batch_size=BATCH_EVAL,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    logging_steps=50,\n",
    "    evaluation=\"epoch\",\n",
    "    save=\"no\",\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    ")\n",
    "\n",
    "def compute_metrics_t3(eval_pred):\n",
    "    logits = eval_pred.predictions[0] if isinstance(eval_pred.predictions, (list, tuple)) else eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits))\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    return {\"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0)}\n",
    "\n",
    "trainer_t3 = WeightedTrainerT3(\n",
    "    model=mdl_t3,\n",
    "    args=args_t3,\n",
    "    train_dataset=ds_t3_train,\n",
    "    eval_dataset=ds_t3_train,  # on TRAIN\n",
    "    tokenizer=tok_t3,\n",
    "    data_collator=DataCollatorWithPadding(tok_t3),\n",
    "    compute_metrics=compute_metrics_t3,\n",
    "    pos_weight=pos_weight_3,\n",
    ")\n",
    "\n",
    "print(\"Subtask 3 (DeBERTa) trainer device:\", trainer_t3.args.device)\n",
    "\n",
    "# 5.6 Train + raw F1 (0.5 thr) on TRAIN\n",
    "trainer_t3.train()\n",
    "eval_t3_train_raw = trainer_t3.evaluate()\n",
    "print(\"T3 Macro-F1 (TRAIN, thr=0.5):\", eval_t3_train_raw.get(\"eval_f1_macro\"))\n",
    "\n",
    "# 5.7 Calibrate temperature + thresholds on TRAIN\n",
    "logits_t3_train, labels_t3_train = collect_logits(trainer_t3, ds_t3_train, is_multilabel=True)\n",
    "T_t3 = learn_temperature(logits_t3_train, labels_t3_train, is_multilabel=True)\n",
    "probs_t3_train = torch.sigmoid(logits_t3_train / T_t3).cpu().numpy()\n",
    "thr_map_t3 = grid_search_thresholds(labels_t3_train.cpu().numpy(), probs_t3_train, T3_LABELS)\n",
    "\n",
    "P3_train = np.zeros_like(probs_t3_train, dtype=int)\n",
    "for j, lab in enumerate(T3_LABELS):\n",
    "    P3_train[:, j] = (probs_t3_train[:, j] >= thr_map_t3[lab]).astype(int)\n",
    "f1_t3_cal = f1_score(labels_t3_train.cpu().numpy(), P3_train, average=\"macro\", zero_division=0)\n",
    "print(\"T3 temperature:\", T_t3)\n",
    "print(\"T3 thresholds:\", thr_map_t3)\n",
    "print(\"T3 Macro-F1 (TRAIN, calibrated):\", f1_t3_cal)\n",
    "\n",
    "# 5.8 Save model + calibration\n",
    "mdl_t3.save_pretrained(ART_ROOT / \"native_t3\")\n",
    "tok_t3.save_pretrained(ART_ROOT / \"native_t3\")\n",
    "with open(ART_ROOT / \"calib_t3_native.json\", \"w\") as f:\n",
    "    json.dump({\"temperature\": float(T_t3), \"thresholds\": thr_map_t3}, f, indent=2)\n",
    "\n",
    "# 5.9 Infer on DEV, cache probs, build submission CSV\n",
    "preds_dev_t3 = trainer_t3.predict(ds_t3_dev)\n",
    "logits_t3_dev = torch.tensor(preds_dev_t3.predictions if not isinstance(preds_dev_t3.predictions,(list,tuple)) else preds_dev_t3.predictions[0])\n",
    "probs_t3_dev = torch.sigmoid(logits_t3_dev / T_t3).cpu().numpy()\n",
    "\n",
    "P3_dev = np.zeros_like(probs_t3_dev, dtype=int)\n",
    "for j, lab in enumerate(T3_LABELS):\n",
    "    P3_dev[:, j] = (probs_t3_dev[:, j] >= thr_map_t3[lab]).astype(int)\n",
    "\n",
    "# Cache for ensemble\n",
    "train_cols3 = {\"id\": t3_train_df[\"id\"].astype(str)}\n",
    "for j, lab in enumerate(T3_LABELS):\n",
    "    train_cols3[f\"prob_{lab}\"] = probs_t3_train[:, j]\n",
    "    train_cols3[f\"label_{lab}\"] = labels_t3_train.cpu().numpy()[:, j]\n",
    "cache_t3_train = pd.DataFrame(train_cols3)\n",
    "cache_t3_train.to_csv(CACHE_ROOT / \"t3_train_probs.csv\", index=False)\n",
    "\n",
    "dev_cols3 = {\"id\": t3_dev_df[\"id\"].astype(str)}\n",
    "for j, lab in enumerate(T3_LABELS):\n",
    "    dev_cols3[f\"prob_{lab}\"] = probs_t3_dev[:, j]\n",
    "cache_t3_dev = pd.DataFrame(dev_cols3)\n",
    "cache_t3_dev.to_csv(CACHE_ROOT / \"t3_dev_probs.csv\", index=False)\n",
    "\n",
    "# Submission CSV for subtask 3\n",
    "# Codabench header: id,stereotype,vilification,dehumanization,extreme_language,lack_of_empathy,invalidation\n",
    "idx3 = {lab: i for i, lab in enumerate(T3_LABELS)}\n",
    "sub3 = pd.DataFrame({\n",
    "    \"id\": t3_dev_df[\"id\"].astype(str),\n",
    "    \"stereotype\":       P3_dev[:, idx3[\"stereotype\"]],\n",
    "    \"vilification\":     P3_dev[:, idx3[\"vilification\"]],\n",
    "    \"dehumanization\":   P3_dev[:, idx3[\"dehumanization\"]],\n",
    "    \"extreme_language\": P3_dev[:, idx3[\"extreme_language\"]],\n",
    "    \"lack_of_empathy\":  P3_dev[:, idx3[\"lack_of_empathy\"]],\n",
    "    \"invalidation\":     P3_dev[:, idx3[\"invalidation\"]],\n",
    "})\n",
    "sub3_path = SUB_ROOT / \"subtask_3\" / f\"pred_{lang_fname}.csv\"\n",
    "sub3.to_csv(sub3_path, index=False)\n",
    "print(\"Wrote Subtask 3 submission CSV:\", sub3_path)\n",
    "\n",
    "print(\"\\nAll DeBERTa training + calibration + dev submissions done.\")\n",
    "print(\"Submission roots (zip one subtask folder at a time for Codabench):\")\n",
    "print(\"  \", SUB_ROOT / \"subtask_1\")\n",
    "print(\"  \", SUB_ROOT / \"subtask_2\")\n",
    "print(\"  \", SUB_ROOT / \"subtask_3\")\n",
    "print(\"Caches for ensembling live under:\", CACHE_ROOT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
