{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e433bd36",
   "metadata": {},
   "source": [
    "## Setup, device, config, directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b421098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 18:15:20.166559: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765160120.180386 3936315 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765160120.184496 3936315 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1765160120.197176 3936315 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765160120.197192 3936315 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765160120.197194 3936315 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765160120.197195 3936315 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.0\n",
      "Transformers: 4.57.1\n",
      "Using GPU: NVIDIA H100 80GB HBM3 MIG 2g.20gb\n",
      "Artifacts dir: artifacts/xlmr/eng\n",
      "Outputs dir: outputs/xlmr/eng\n",
      "Submission dirs: submissions/xlmr/subtask_1 submissions/xlmr/subtask_2 submissions/xlmr/subtask_3\n",
      "Cache dir (for ensembling): cache/xlmr/eng\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 0) Setup: env, device, config\n",
    "# ============================\n",
    "\n",
    "import os\n",
    "\n",
    "# Prevent TensorFlow / Flax imports (avoids tf-keras noise & slow init)\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import json, random, warnings, inspect\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, DataCollatorWithPadding\n",
    ")\n",
    "import transformers\n",
    "\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"Transformers:\", transformers.__version__)\n",
    "\n",
    "# ---- Device selection (GPU / CPU toggle) ----\n",
    "RUN_DEVICE = \"gpu\"  # \"gpu\" or \"cpu\"\n",
    "\n",
    "if RUN_DEVICE.lower() == \"gpu\" and torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.set_num_threads(max(1, os.cpu_count() // 2))\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# ---- Seeds ----\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if DEVICE.type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ============================\n",
    "# Config\n",
    "# ============================\n",
    "\n",
    "METHOD      = \"xlmr\"              # method name (for folder structure)\n",
    "LANG        = \"eng\"               # e.g. \"eng\" | \"ben\" | \"hin\"\n",
    "MODEL_NAME  = \"xlm-roberta-base\"  # multilingual encoder\n",
    "\n",
    "MAX_LEN      = 192\n",
    "EPOCHS       = 3\n",
    "LR           = 2e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "WARMUP_RATIO = 0.1\n",
    "GRAD_ACCUM   = 4\n",
    "\n",
    "BATCH_TRAIN_GPU = 8\n",
    "BATCH_TRAIN_CPU = 4\n",
    "BATCH_EVAL_GPU  = 16\n",
    "BATCH_EVAL_CPU  = 8\n",
    "\n",
    "BATCH_TRAIN = BATCH_TRAIN_GPU if DEVICE.type == \"cuda\" else BATCH_TRAIN_CPU\n",
    "BATCH_EVAL  = BATCH_EVAL_GPU  if DEVICE.type == \"cuda\" else BATCH_EVAL_CPU\n",
    "\n",
    "BASE = \"../dev_phase\"  # organizer data root\n",
    "\n",
    "lang_fname = LANG if LANG != \"eng\" else \"eng\"\n",
    "\n",
    "# ============================\n",
    "# Data paths: TRAIN (labeled) / DEV (unlabeled)\n",
    "# ============================\n",
    "\n",
    "# Subtask 1 (binary)\n",
    "T1_TRAIN = f\"{BASE}/subtask1/train/{lang_fname}.csv\"\n",
    "T1_DEV   = f\"{BASE}/subtask1/dev/{lang_fname}.csv\"   # unlabeled dev\n",
    "\n",
    "# Subtask 2 (multi-label 5)\n",
    "T2_TRAIN = f\"{BASE}/subtask2/train/{lang_fname}.csv\"\n",
    "T2_DEV   = f\"{BASE}/subtask2/dev/{lang_fname}.csv\"\n",
    "\n",
    "# Subtask 3 (multi-label 6)\n",
    "T3_TRAIN = f\"{BASE}/subtask3/train/{lang_fname}.csv\"\n",
    "T3_DEV   = f\"{BASE}/subtask3/dev/{lang_fname}.csv\"\n",
    "\n",
    "# ============================\n",
    "# Directories (method-aware)\n",
    "# ============================\n",
    "\n",
    "ART_DIR_ROOT    = Path(\"artifacts\")\n",
    "OUT_DIR_ROOT    = Path(\"outputs\")\n",
    "SUBMIT_ROOT     = Path(\"submissions\")\n",
    "CACHE_ROOT      = Path(\"cache\")\n",
    "\n",
    "ART_DIR   = ART_DIR_ROOT / METHOD / LANG\n",
    "OUT_DIR   = OUT_DIR_ROOT / METHOD / LANG\n",
    "METHOD_SUBMIT_DIR = SUBMIT_ROOT / METHOD\n",
    "CACHE_DIR = CACHE_ROOT / METHOD / LANG\n",
    "\n",
    "for d in [ART_DIR, OUT_DIR, METHOD_SUBMIT_DIR, CACHE_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Subtask-specific submission dirs:\n",
    "SUB1_DIR = METHOD_SUBMIT_DIR / \"subtask_1\"\n",
    "SUB2_DIR = METHOD_SUBMIT_DIR / \"subtask_2\"\n",
    "SUB3_DIR = METHOD_SUBMIT_DIR / \"subtask_3\"\n",
    "for d in [SUB1_DIR, SUB2_DIR, SUB3_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Artifacts dir:\", ART_DIR)\n",
    "print(\"Outputs dir:\", OUT_DIR)\n",
    "print(\"Submission dirs:\", SUB1_DIR, SUB2_DIR, SUB3_DIR)\n",
    "print(\"Cache dir (for ensembling):\", CACHE_DIR)\n",
    "\n",
    "# Label orders in TRAIN (used internally)\n",
    "T2_LABELS = [\"gender/sexual\",\"political\",\"religious\",\"racial/ethnic\",\"other\"]\n",
    "T3_LABELS = [\"vilification\",\"extreme_language\",\"stereotype\",\n",
    "             \"invalidation\",\"lack_of_empathy\",\"dehumanization\"]\n",
    "\n",
    "# ============================\n",
    "# TrainingArguments capability detection\n",
    "# ============================\n",
    "\n",
    "_TA_PARAMS = inspect.signature(TrainingArguments.__init__).parameters\n",
    "TRAINER_CAPS = {\n",
    "    \"evaluation_strategy\": \"evaluation_strategy\" in _TA_PARAMS,\n",
    "    \"save_strategy\":       \"save_strategy\" in _TA_PARAMS,\n",
    "    \"warmup_ratio\":        \"warmup_ratio\" in _TA_PARAMS,\n",
    "    \"fp16\":                \"fp16\" in _TA_PARAMS,\n",
    "    \"no_cuda\":             \"no_cuda\" in _TA_PARAMS,\n",
    "    \"use_mps_device\":      \"use_mps_device\" in _TA_PARAMS,\n",
    "    \"report_to\":           \"report_to\" in _TA_PARAMS,\n",
    "    \"grad_accum\":          \"gradient_accumulation_steps\" in _TA_PARAMS,\n",
    "    \"eval_accum\":          \"eval_accumulation_steps\" in _TA_PARAMS,\n",
    "}\n",
    "\n",
    "def build_training_args(output_dir, per_device_train_batch_size, per_device_eval_batch_size,\n",
    "                        num_train_epochs, learning_rate, weight_decay, logging_steps=50,\n",
    "                        evaluation=\"epoch\", save=\"no\", warmup_ratio=WARMUP_RATIO, warmup_steps=0):\n",
    "    use_cuda_flag = (DEVICE.type == \"cuda\")\n",
    "\n",
    "    kwargs = dict(\n",
    "        output_dir=str(output_dir),\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        logging_steps=logging_steps,\n",
    "        dataloader_pin_memory=use_cuda_flag,\n",
    "        dataloader_num_workers=0,\n",
    "    )\n",
    "    if TRAINER_CAPS[\"evaluation_strategy\"]:\n",
    "        kwargs[\"evaluation_strategy\"] = evaluation\n",
    "    if TRAINER_CAPS[\"save_strategy\"]:\n",
    "        kwargs[\"save_strategy\"] = save\n",
    "    if TRAINER_CAPS[\"warmup_ratio\"]:\n",
    "        kwargs[\"warmup_ratio\"] = warmup_ratio\n",
    "    else:\n",
    "        kwargs[\"warmup_steps\"] = warmup_steps\n",
    "    if TRAINER_CAPS[\"fp16\"]:\n",
    "        kwargs[\"fp16\"] = False   # keep simple/stable\n",
    "    if TRAINER_CAPS[\"no_cuda\"]:\n",
    "        kwargs[\"no_cuda\"] = not use_cuda_flag\n",
    "    if TRAINER_CAPS[\"use_mps_device\"]:\n",
    "        kwargs[\"use_mps_device\"] = False\n",
    "    if TRAINER_CAPS[\"report_to\"]:\n",
    "        kwargs[\"report_to\"] = \"none\"\n",
    "    if TRAINER_CAPS[\"grad_accum\"]:\n",
    "        kwargs[\"gradient_accumulation_steps\"] = GRAD_ACCUM\n",
    "    if TRAINER_CAPS[\"eval_accum\"]:\n",
    "        kwargs[\"eval_accumulation_steps\"] = 8\n",
    "\n",
    "    return TrainingArguments(**kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a06d1c5",
   "metadata": {},
   "source": [
    "## Dataset class, metrics, calibration helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e17794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1) Dataset + helpers\n",
    "# ============================\n",
    "\n",
    "class TextClsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=256, is_multilabel=False):\n",
    "        self.texts = list(texts)\n",
    "        self.labels = labels  # list/array\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.is_multilabel = is_multilabel\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=False,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        y = self.labels[idx]\n",
    "        item[\"labels\"] = torch.tensor(\n",
    "            y,\n",
    "            dtype=torch.float if self.is_multilabel else torch.long,\n",
    "        )\n",
    "        return item\n",
    "\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "\n",
    "def grid_search_thresholds(y_true, y_prob, label_names=None):\n",
    "    \"\"\"\n",
    "    Per-label threshold search (multi-label).\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    C = y_true.shape[1]\n",
    "    grid = np.linspace(0.05, 0.95, 19)\n",
    "    thrs = {}\n",
    "    for c in range(C):\n",
    "        best_t, best_f = 0.5, -1.0\n",
    "        for t in grid:\n",
    "            preds = (y_prob[:, c] >= t).astype(int)\n",
    "            f = f1_score(y_true[:, c], preds, average=\"binary\", zero_division=0)\n",
    "            if f > best_f:\n",
    "                best_f, best_t = f, t\n",
    "        name = label_names[c] if label_names else str(c)\n",
    "        thrs[name] = float(best_t)\n",
    "    return thrs\n",
    "\n",
    "\n",
    "class TempScaler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.T = nn.Parameter(torch.ones(1))\n",
    "\n",
    "    def forward(self, logits):\n",
    "        return logits / self.T\n",
    "\n",
    "\n",
    "def learn_temperature(train_logits, train_labels, is_multilabel):\n",
    "    \"\"\"\n",
    "    Learn a single temperature scalar on TRAIN logits.\n",
    "    \"\"\"\n",
    "    device = DEVICE\n",
    "    scaler = TempScaler().to(device)\n",
    "    train_logits = train_logits.to(device)\n",
    "    train_labels = train_labels.to(device)\n",
    "    opt = torch.optim.LBFGS([scaler.T], max_iter=50)\n",
    "    criterion = nn.BCEWithLogitsLoss() if is_multilabel else nn.CrossEntropyLoss()\n",
    "\n",
    "    def closure():\n",
    "        opt.zero_grad()\n",
    "        z = scaler(train_logits)\n",
    "        loss = criterion(z, train_labels.float() if is_multilabel else train_labels.long())\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    opt.step(closure)\n",
    "    return float(scaler.T.detach().cpu().item())\n",
    "\n",
    "\n",
    "def collect_logits(trainer, dataset, is_multilabel):\n",
    "    \"\"\"\n",
    "    Collect logits + labels from trainer.predict(dataset).\n",
    "    \"\"\"\n",
    "    preds = trainer.predict(dataset)\n",
    "    if isinstance(preds.predictions, (list, tuple)):\n",
    "        logits_arr = preds.predictions[0]\n",
    "    else:\n",
    "        logits_arr = preds.predictions\n",
    "    logits = torch.tensor(logits_arr)\n",
    "    labels = torch.tensor(preds.label_ids)\n",
    "    if not is_multilabel and logits.ndim == 1:\n",
    "        logits = logits.unsqueeze(1)\n",
    "    return logits, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c38dd3",
   "metadata": {},
   "source": [
    "## Subtask 1: train, calibrate on train, infer dev, cache, submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d97857f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T1] TRAIN size: 3222\n",
      "[T1] DEV size (unlabeled): 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer T1 device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='303' max='303' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [303/303 00:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.647700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.592400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.530400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.496600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.411500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.441400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T1] Macro-F1 (TRAIN, argmax): 0.835714586127454\n",
      "[T1] calibration (TRAIN): T=0.9626, best_thr=0.45, train_macroF1@thr=0.8371\n",
      "Saved T1 TRAIN probs to cache: cache/xlmr/eng/t1_train_probs.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved T1 DEV probs to cache: cache/xlmr/eng/t1_dev_probs.csv\n",
      "Saved Codabench file (Subtask 1, XLM-R): submissions/xlmr/subtask_1/pred_eng.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 2) Subtask 1 — Polarization (binary)\n",
    "# ============================\n",
    "\n",
    "# 2.1 Load TRAIN (labeled) + DEV (unlabeled)\n",
    "t1_train_df = pd.read_csv(T1_TRAIN)\n",
    "t1_dev_df   = pd.read_csv(T1_DEV)\n",
    "\n",
    "required_cols_t1_train = {\"id\", \"text\", \"polarization\"}\n",
    "required_cols_t1_dev   = {\"id\", \"text\"}  # dev has no labels\n",
    "assert required_cols_t1_train.issubset(t1_train_df.columns), \\\n",
    "    f\"T1 TRAIN missing: {required_cols_t1_train - set(t1_train_df.columns)}\"\n",
    "assert required_cols_t1_dev.issubset(t1_dev_df.columns), \\\n",
    "    f\"T1 DEV missing: {required_cols_t1_dev - set(t1_dev_df.columns)}\"\n",
    "\n",
    "t1_train_df[\"polarization\"] = t1_train_df[\"polarization\"].astype(int)\n",
    "\n",
    "print(f\"[T1] TRAIN size: {len(t1_train_df)}\")\n",
    "print(f\"[T1] DEV size (unlabeled): {len(t1_dev_df)}\")\n",
    "\n",
    "# 2.2 Tokenizer & model\n",
    "tok_t1 = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "cfg_t1 = AutoConfig.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "mdl_t1 = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=cfg_t1)\n",
    "mdl_t1.config.use_cache = False\n",
    "if hasattr(mdl_t1, \"gradient_checkpointing_enable\"):\n",
    "    mdl_t1.gradient_checkpointing_enable()\n",
    "mdl_t1.to(DEVICE)\n",
    "\n",
    "# 2.3 Datasets\n",
    "ds_t1_train = TextClsDataset(\n",
    "    t1_train_df[\"text\"],\n",
    "    t1_train_df[\"polarization\"],\n",
    "    tok_t1,\n",
    "    MAX_LEN,\n",
    "    False,\n",
    ")\n",
    "\n",
    "# For DEV inference we use dummy labels (all zeros)\n",
    "dummy_labels_t1_dev = np.zeros(len(t1_dev_df), dtype=int)\n",
    "ds_t1_dev_infer = TextClsDataset(\n",
    "    t1_dev_df[\"text\"],\n",
    "    dummy_labels_t1_dev,\n",
    "    tok_t1,\n",
    "    MAX_LEN,\n",
    "    False,\n",
    ")\n",
    "\n",
    "# 2.4 Trainer (eval on TRAIN)\n",
    "args_t1 = build_training_args(\n",
    "    output_dir=ART_DIR / \"t1_tmp\",\n",
    "    per_device_train_batch_size=BATCH_TRAIN,\n",
    "    per_device_eval_batch_size=BATCH_EVAL,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    logging_steps=50,\n",
    "    evaluation=\"epoch\",\n",
    "    save=\"no\",\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    ")\n",
    "\n",
    "def compute_metrics_t1(eval_pred):\n",
    "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\"f1_macro\": macro_f1(labels, preds)}\n",
    "\n",
    "trainer_t1 = Trainer(\n",
    "    model=mdl_t1,\n",
    "    args=args_t1,\n",
    "    train_dataset=ds_t1_train,\n",
    "    eval_dataset=ds_t1_train,  # eval on TRAIN\n",
    "    tokenizer=tok_t1,\n",
    "    data_collator=DataCollatorWithPadding(tok_t1),\n",
    "    compute_metrics=compute_metrics_t1,\n",
    ")\n",
    "print(\"Trainer T1 device:\", trainer_t1.args.device)\n",
    "\n",
    "# 2.5 Train + F1 on TRAIN (argmax)\n",
    "trainer_t1.train()\n",
    "eval_t1_train = trainer_t1.evaluate()\n",
    "print(\"[T1] Macro-F1 (TRAIN, argmax):\", eval_t1_train.get(\"eval_f1_macro\"))\n",
    "\n",
    "# 2.6 Calibration on TRAIN (temperature + global threshold)\n",
    "logits_t1_train, labels_t1_train = collect_logits(\n",
    "    trainer_t1,\n",
    "    ds_t1_train,\n",
    "    is_multilabel=False,\n",
    ")\n",
    "T_t1 = learn_temperature(logits_t1_train, labels_t1_train, is_multilabel=False)\n",
    "probs_t1_train = torch.softmax(logits_t1_train / T_t1, dim=1)[:, 1].cpu().numpy()\n",
    "\n",
    "best_thr_t1, best_f1_train = 0.5, -1.0\n",
    "for t in np.linspace(0.05, 0.95, 19):\n",
    "    pred = (probs_t1_train >= t).astype(int)\n",
    "    f = macro_f1(labels_t1_train.numpy(), pred)\n",
    "    if f > best_f1_train:\n",
    "        best_f1_train, best_thr_t1 = f, t\n",
    "\n",
    "print(\n",
    "    f\"[T1] calibration (TRAIN): T={T_t1:.4f}, \"\n",
    "    f\"best_thr={best_thr_t1:.2f}, train_macroF1@thr={best_f1_train:.4f}\"\n",
    ")\n",
    "\n",
    "# 2.7 Cache TRAIN probabilities for ensembling\n",
    "t1_train_cache = pd.DataFrame({\n",
    "    \"id\":   t1_train_df[\"id\"].astype(str).values,\n",
    "    \"prob_pos\": probs_t1_train,\n",
    "    \"label\":   labels_t1_train.numpy(),\n",
    "})\n",
    "t1_train_cache_path = CACHE_DIR / f\"t1_train_probs.csv\"\n",
    "t1_train_cache.to_csv(t1_train_cache_path, index=False)\n",
    "print(\"Saved T1 TRAIN probs to cache:\", t1_train_cache_path)\n",
    "\n",
    "# 2.8 Inference on DEV (unlabeled) + cache DEV probabilities\n",
    "logits_t1_dev, _ = collect_logits(\n",
    "    trainer_t1,\n",
    "    ds_t1_dev_infer,\n",
    "    is_multilabel=False,\n",
    ")\n",
    "probs_t1_dev = torch.softmax(logits_t1_dev / T_t1, dim=1)[:, 1].cpu().numpy()\n",
    "pred1_dev = (probs_t1_dev >= best_thr_t1).astype(int)\n",
    "\n",
    "t1_dev_cache = pd.DataFrame({\n",
    "    \"id\":      t1_dev_df[\"id\"].astype(str).values,\n",
    "    \"prob_pos\": probs_t1_dev,\n",
    "})\n",
    "t1_dev_cache_path = CACHE_DIR / f\"t1_dev_probs.csv\"\n",
    "t1_dev_cache.to_csv(t1_dev_cache_path, index=False)\n",
    "print(\"Saved T1 DEV probs to cache:\", t1_dev_cache_path)\n",
    "\n",
    "# 2.9 Save model + calibration\n",
    "trainer_t1.save_model(ART_DIR / f\"native_t1\")\n",
    "with open(ART_DIR / f\"calib_t1_native.json\",\"w\") as f:\n",
    "    json.dump(\n",
    "        {\"temperature\": float(T_t1), \"threshold\": float(best_thr_t1)},\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "# 2.10 Write Codabench submission CSV for Subtask 1\n",
    "sub1 = pd.DataFrame({\n",
    "    \"id\":           t1_dev_df[\"id\"].astype(str).values,\n",
    "    \"polarization\": pred1_dev.astype(int),\n",
    "})\n",
    "sub1_path = SUB1_DIR / f\"pred_{LANG}.csv\"\n",
    "sub1.to_csv(sub1_path, index=False)\n",
    "print(\"Saved Codabench file (Subtask 1, XLM-R):\", sub1_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea4ffab",
   "metadata": {},
   "source": [
    "## Subtask 2: train, calibrate on train, infer dev, cache, submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdec95a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T2] TRAIN size: 3222\n",
      "[T2] DEV size (unlabeled): 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer T2 device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='303' max='303' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [303/303 00:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.227400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.253300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.129400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.063500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.998500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.920200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T2] Macro-F1 (TRAIN, thr=0.5): 0.33029032232449357\n",
      "[T2] calibration (TRAIN):\n",
      "  temperature: 0.7747967839241028\n",
      "  thresholds: {'gender/sexual': 0.85, 'political': 0.35, 'religious': 0.95, 'racial/ethnic': 0.9, 'other': 0.7}\n",
      "  Macro-F1 (TRAIN, calibrated): 0.4713820066883467\n",
      "Saved T2 TRAIN probs to cache: cache/xlmr/eng/t2_train_probs.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved T2 DEV probs to cache: cache/xlmr/eng/t2_dev_probs.csv\n",
      "Saved Codabench file (Subtask 2, XLM-R): submissions/xlmr/subtask_2/pred_eng.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 3) Subtask 2 — Hate type (multi-label 5)\n",
    "# ============================\n",
    "\n",
    "# 3.1 Load TRAIN (labeled) + DEV (unlabeled)\n",
    "t2_train_df = pd.read_csv(T2_TRAIN)\n",
    "t2_dev_df   = pd.read_csv(T2_DEV)\n",
    "\n",
    "required_cols_t2_train = {\"id\", \"text\", *T2_LABELS}\n",
    "required_cols_t2_dev   = {\"id\", \"text\"}  # dev has no labels\n",
    "assert required_cols_t2_train.issubset(t2_train_df.columns), \\\n",
    "    f\"T2 TRAIN missing: {required_cols_t2_train - set(t2_train_df.columns)}\"\n",
    "assert required_cols_t2_dev.issubset(t2_dev_df.columns), \\\n",
    "    f\"T2 DEV missing: {required_cols_t2_dev - set(t2_dev_df.columns)}\"\n",
    "\n",
    "Y2_train = t2_train_df[T2_LABELS].values.astype(int)\n",
    "\n",
    "print(f\"[T2] TRAIN size: {len(t2_train_df)}\")\n",
    "print(f\"[T2] DEV size (unlabeled): {len(t2_dev_df)}\")\n",
    "\n",
    "# 3.2 Tokenizer & model\n",
    "tok_t2 = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "cfg_t2 = AutoConfig.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(T2_LABELS),\n",
    "    problem_type=\"multi_label_classification\",\n",
    ")\n",
    "mdl_t2 = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=cfg_t2)\n",
    "mdl_t2.config.use_cache = False\n",
    "if hasattr(mdl_t2, \"gradient_checkpointing_enable\"):\n",
    "    mdl_t2.gradient_checkpointing_enable()\n",
    "mdl_t2.to(DEVICE)\n",
    "\n",
    "# 3.3 Datasets\n",
    "ds_t2_train = TextClsDataset(\n",
    "    t2_train_df[\"text\"],\n",
    "    Y2_train.tolist(),\n",
    "    tok_t2,\n",
    "    MAX_LEN,\n",
    "    True,\n",
    ")\n",
    "\n",
    "dummy_labels_t2_dev = np.zeros((len(t2_dev_df), len(T2_LABELS)), dtype=int)\n",
    "ds_t2_dev_infer = TextClsDataset(\n",
    "    t2_dev_df[\"text\"],\n",
    "    dummy_labels_t2_dev.tolist(),\n",
    "    tok_t2,\n",
    "    MAX_LEN,\n",
    "    True,\n",
    ")\n",
    "\n",
    "# 3.4 pos_weight for imbalance (on TRAIN)\n",
    "pos_count_2 = Y2_train.sum(axis=0) + 1e-6\n",
    "neg_count_2 = Y2_train.shape[0] - pos_count_2\n",
    "pos_weight_2 = torch.tensor(neg_count_2 / pos_count_2, dtype=torch.float)\n",
    "\n",
    "class WeightedTrainerT2(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = nn.BCEWithLogitsLoss(pos_weight=pos_weight_2.to(logits.device))\n",
    "        loss = loss_fct(logits, labels.to(logits.device).float())\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "args_t2 = build_training_args(\n",
    "    output_dir=ART_DIR / \"t2_tmp\",\n",
    "    per_device_train_batch_size=BATCH_TRAIN,\n",
    "    per_device_eval_batch_size=BATCH_EVAL,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    logging_steps=50,\n",
    "    evaluation=\"epoch\",\n",
    "    save=\"no\",\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    ")\n",
    "\n",
    "def compute_metrics_t2(eval_pred):\n",
    "    logits = eval_pred.predictions[0] if isinstance(\n",
    "        eval_pred.predictions, (tuple, list)\n",
    "    ) else eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "    probs  = 1.0 / (1.0 + np.exp(-logits))\n",
    "    preds  = (probs >= 0.5).astype(int)\n",
    "    return {\"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0)}\n",
    "\n",
    "trainer_t2 = WeightedTrainerT2(\n",
    "    model=mdl_t2,\n",
    "    args=args_t2,\n",
    "    train_dataset=ds_t2_train,\n",
    "    eval_dataset=ds_t2_train,  # eval on TRAIN\n",
    "    tokenizer=tok_t2,\n",
    "    data_collator=DataCollatorWithPadding(tok_t2),\n",
    "    compute_metrics=compute_metrics_t2,\n",
    ")\n",
    "print(\"Trainer T2 device:\", trainer_t2.args.device)\n",
    "\n",
    "# 3.5 Train + F1 on TRAIN @0.5\n",
    "trainer_t2.train()\n",
    "eval_t2_train = trainer_t2.evaluate()\n",
    "print(\"[T2] Macro-F1 (TRAIN, thr=0.5):\", eval_t2_train.get(\"eval_f1_macro\"))\n",
    "\n",
    "# 3.6 Calibration on TRAIN (temperature + per-label thresholds)\n",
    "logits_t2_train, labels_t2_train = collect_logits(\n",
    "    trainer_t2,\n",
    "    ds_t2_train,\n",
    "    is_multilabel=True,\n",
    ")\n",
    "T_t2 = learn_temperature(logits_t2_train, labels_t2_train, is_multilabel=True)\n",
    "probs_t2_train = torch.sigmoid(logits_t2_train / T_t2).cpu().numpy()\n",
    "\n",
    "thr_map_t2 = grid_search_thresholds(labels_t2_train.numpy(), probs_t2_train, T2_LABELS)\n",
    "\n",
    "P2_train = np.zeros_like(probs_t2_train, dtype=int)\n",
    "for j, lab in enumerate(T2_LABELS):\n",
    "    thr = float(thr_map_t2[lab])\n",
    "    P2_train[:, j] = (probs_t2_train[:, j] >= thr).astype(int)\n",
    "\n",
    "train_f1_calib_t2 = f1_score(labels_t2_train.numpy(), P2_train, average=\"macro\", zero_division=0)\n",
    "print(\"[T2] calibration (TRAIN):\")\n",
    "print(\"  temperature:\", T_t2)\n",
    "print(\"  thresholds:\", thr_map_t2)\n",
    "print(\"  Macro-F1 (TRAIN, calibrated):\", train_f1_calib_t2)\n",
    "\n",
    "# 3.7 Cache TRAIN probabilities for ensembling\n",
    "cache_cols_train_t2 = {\"id\": t2_train_df[\"id\"].astype(str).values}\n",
    "for j, lab in enumerate(T2_LABELS):\n",
    "    cache_cols_train_t2[f\"prob_{lab}\"] = probs_t2_train[:, j]\n",
    "    cache_cols_train_t2[f\"label_{lab}\"] = labels_t2_train.numpy()[:, j]\n",
    "\n",
    "t2_train_cache = pd.DataFrame(cache_cols_train_t2)\n",
    "t2_train_cache_path = CACHE_DIR / f\"t2_train_probs.csv\"\n",
    "t2_train_cache.to_csv(t2_train_cache_path, index=False)\n",
    "print(\"Saved T2 TRAIN probs to cache:\", t2_train_cache_path)\n",
    "\n",
    "# 3.8 Inference on DEV (unlabeled) + cache DEV probs\n",
    "logits_t2_dev, _ = collect_logits(\n",
    "    trainer_t2,\n",
    "    ds_t2_dev_infer,\n",
    "    is_multilabel=True,\n",
    ")\n",
    "probs_t2_dev = torch.sigmoid(logits_t2_dev / T_t2).cpu().numpy()\n",
    "\n",
    "P2_dev = np.zeros_like(probs_t2_dev, dtype=int)\n",
    "for j, lab in enumerate(T2_LABELS):\n",
    "    thr = float(thr_map_t2[lab])\n",
    "    P2_dev[:, j] = (probs_t2_dev[:, j] >= thr).astype(int)\n",
    "\n",
    "cache_cols_dev_t2 = {\"id\": t2_dev_df[\"id\"].astype(str).values}\n",
    "for j, lab in enumerate(T2_LABELS):\n",
    "    cache_cols_dev_t2[f\"prob_{lab}\"] = probs_t2_dev[:, j]\n",
    "t2_dev_cache = pd.DataFrame(cache_cols_dev_t2)\n",
    "t2_dev_cache_path = CACHE_DIR / f\"t2_dev_probs.csv\"\n",
    "t2_dev_cache.to_csv(t2_dev_cache_path, index=False)\n",
    "print(\"Saved T2 DEV probs to cache:\", t2_dev_cache_path)\n",
    "\n",
    "# 3.9 Save model + calibration\n",
    "trainer_t2.save_model(ART_DIR / f\"native_t2\")\n",
    "with open(ART_DIR / f\"calib_t2_native.json\",\"w\") as f:\n",
    "    json.dump(\n",
    "        {\"temperature\": float(T_t2), \"thresholds\": thr_map_t2},\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "# 3.10 Write Codabench submission CSV for Subtask 2\n",
    "# Required header: id,political,racial/ethnic,religious,gender/sexual,other\n",
    "\n",
    "idx_gender    = T2_LABELS.index(\"gender/sexual\")\n",
    "idx_political = T2_LABELS.index(\"political\")\n",
    "idx_religious = T2_LABELS.index(\"religious\")\n",
    "idx_racial    = T2_LABELS.index(\"racial/ethnic\")\n",
    "idx_other     = T2_LABELS.index(\"other\")\n",
    "\n",
    "sub2 = pd.DataFrame({\n",
    "    \"id\":            t2_dev_df[\"id\"].astype(str).values,\n",
    "    \"political\":     P2_dev[:, idx_political],\n",
    "    \"racial/ethnic\": P2_dev[:, idx_racial],\n",
    "    \"religious\":     P2_dev[:, idx_religious],\n",
    "    \"gender/sexual\": P2_dev[:, idx_gender],\n",
    "    \"other\":         P2_dev[:, idx_other],\n",
    "})\n",
    "sub2_path = SUB2_DIR / f\"pred_{LANG}.csv\"\n",
    "sub2.to_csv(sub2_path, index=False)\n",
    "print(\"Saved Codabench file (Subtask 2, XLM-R):\", sub2_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9db1ca",
   "metadata": {},
   "source": [
    "## Subtask 3: train, calibrate on train, infer dev, cache, submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c77a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T3] TRAIN size: 3222\n",
      "[T3] DEV size (unlabeled): 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer T3 device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='303' max='303' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [303/303 00:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.132900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.142600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.041100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.988700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.942200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.907400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T3] Macro-F1 (TRAIN, thr=0.5): 0.4867891043907717\n",
      "[T3] calibration (TRAIN):\n",
      "  temperature: 1.0684672594070435\n",
      "  thresholds: {'vilification': 0.65, 'extreme_language': 0.6, 'stereotype': 0.7, 'invalidation': 0.65, 'lack_of_empathy': 0.65, 'dehumanization': 0.7}\n",
      "  Macro-F1 (TRAIN, calibrated): 0.5175818625510322\n",
      "Saved T3 TRAIN probs to cache: cache/xlmr/eng/t3_train_probs.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved T3 DEV probs to cache: cache/xlmr/eng/t3_dev_probs.csv\n",
      "Saved Codabench file (Subtask 3, XLM-R): submissions/xlmr/subtask_3/pred_eng.csv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 4) Subtask 3 — Manifestation (multi-label 6)\n",
    "# ============================\n",
    "\n",
    "# 4.1 Load TRAIN (labeled) + DEV (unlabeled)\n",
    "t3_train_df = pd.read_csv(T3_TRAIN)\n",
    "t3_dev_df   = pd.read_csv(T3_DEV)\n",
    "\n",
    "required_cols_t3_train = {\"id\", \"text\", *T3_LABELS}\n",
    "required_cols_t3_dev   = {\"id\", \"text\"}  # dev has no labels\n",
    "assert required_cols_t3_train.issubset(t3_train_df.columns), \\\n",
    "    f\"T3 TRAIN missing: {required_cols_t3_train - set(t3_train_df.columns)}\"\n",
    "assert required_cols_t3_dev.issubset(t3_dev_df.columns), \\\n",
    "    f\"T3 DEV missing: {required_cols_t3_dev - set(t3_dev_df.columns)}\"\n",
    "\n",
    "Y3_train = t3_train_df[T3_LABELS].values.astype(int)\n",
    "\n",
    "print(f\"[T3] TRAIN size: {len(t3_train_df)}\")\n",
    "print(f\"[T3] DEV size (unlabeled): {len(t3_dev_df)}\")\n",
    "\n",
    "# 4.2 Tokenizer & model\n",
    "tok_t3 = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "cfg_t3 = AutoConfig.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(T3_LABELS),\n",
    "    problem_type=\"multi_label_classification\",\n",
    ")\n",
    "mdl_t3 = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=cfg_t3)\n",
    "mdl_t3.config.use_cache = False\n",
    "if hasattr(mdl_t3, \"gradient_checkpointing_enable\"):\n",
    "    mdl_t3.gradient_checkpointing_enable()\n",
    "mdl_t3.to(DEVICE)\n",
    "\n",
    "# 4.3 Datasets\n",
    "ds_t3_train = TextClsDataset(\n",
    "    t3_train_df[\"text\"],\n",
    "    Y3_train.tolist(),\n",
    "    tok_t3,\n",
    "    MAX_LEN,\n",
    "    True,\n",
    ")\n",
    "\n",
    "dummy_labels_t3_dev = np.zeros((len(t3_dev_df), len(T3_LABELS)), dtype=int)\n",
    "ds_t3_dev_infer = TextClsDataset(\n",
    "    t3_dev_df[\"text\"],\n",
    "    dummy_labels_t3_dev.tolist(),\n",
    "    tok_t3,\n",
    "    MAX_LEN,\n",
    "    True,\n",
    ")\n",
    "\n",
    "# 4.4 pos_weight for imbalance (TRAIN)\n",
    "pos_count_3 = Y3_train.sum(axis=0) + 1e-6\n",
    "neg_count_3 = Y3_train.shape[0] - pos_count_3\n",
    "pos_weight_3 = torch.tensor(neg_count_3 / pos_count_3, dtype=torch.float)\n",
    "\n",
    "class WeightedTrainerT3(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = nn.BCEWithLogitsLoss(pos_weight=pos_weight_3.to(logits.device))\n",
    "        loss = loss_fct(logits, labels.to(logits.device).float())\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "args_t3 = build_training_args(\n",
    "    output_dir=ART_DIR / \"t3_tmp\",\n",
    "    per_device_train_batch_size=BATCH_TRAIN,\n",
    "    per_device_eval_batch_size=BATCH_EVAL,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    logging_steps=50,\n",
    "    evaluation=\"epoch\",\n",
    "    save=\"no\",\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    ")\n",
    "\n",
    "def compute_metrics_t3(eval_pred):\n",
    "    logits = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "    probs  = 1.0 / (1.0 + np.exp(-logits))\n",
    "    preds  = (probs >= 0.5).astype(int)\n",
    "    return {\"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0)}\n",
    "\n",
    "trainer_t3 = WeightedTrainerT3(\n",
    "    model=mdl_t3,\n",
    "    args=args_t3,\n",
    "    train_dataset=ds_t3_train,\n",
    "    eval_dataset=ds_t3_train,  # eval on TRAIN\n",
    "    tokenizer=tok_t3,\n",
    "    data_collator=DataCollatorWithPadding(tok_t3),\n",
    "    compute_metrics=compute_metrics_t3,\n",
    ")\n",
    "print(\"Trainer T3 device:\", trainer_t3.args.device)\n",
    "\n",
    "# 4.5 Train + F1 on TRAIN @0.5\n",
    "trainer_t3.train()\n",
    "eval_t3_train = trainer_t3.evaluate()\n",
    "print(\"[T3] Macro-F1 (TRAIN, thr=0.5):\", eval_t3_train.get(\"eval_f1_macro\"))\n",
    "\n",
    "# 4.6 Calibration on TRAIN (temperature + per-label thresholds)\n",
    "logits_t3_train, labels_t3_train = collect_logits(\n",
    "    trainer_t3,\n",
    "    ds_t3_train,\n",
    "    is_multilabel=True,\n",
    ")\n",
    "T_t3 = learn_temperature(logits_t3_train, labels_t3_train, is_multilabel=True)\n",
    "probs_t3_train = torch.sigmoid(logits_t3_train / T_t3).cpu().numpy()\n",
    "\n",
    "thr_map_t3 = grid_search_thresholds(labels_t3_train.numpy(), probs_t3_train, T3_LABELS)\n",
    "\n",
    "P3_train = np.zeros_like(probs_t3_train, dtype=int)\n",
    "for j, lab in enumerate(T3_LABELS):\n",
    "    thr = float(thr_map_t3[lab])\n",
    "    P3_train[:, j] = (probs_t3_train[:, j] >= thr).astype(int)\n",
    "\n",
    "train_f1_calib_t3 = f1_score(labels_t3_train.numpy(), P3_train, average=\"macro\", zero_division=0)\n",
    "print(\"[T3] calibration (TRAIN):\")\n",
    "print(\"  temperature:\", T_t3)\n",
    "print(\"  thresholds:\", thr_map_t3)\n",
    "print(\"  Macro-F1 (TRAIN, calibrated):\", train_f1_calib_t3)\n",
    "\n",
    "# 4.7 Cache TRAIN probabilities for ensembling\n",
    "cache_cols_train_t3 = {\"id\": t3_train_df[\"id\"].astype(str).values}\n",
    "for j, lab in enumerate(T3_LABELS):\n",
    "    cache_cols_train_t3[f\"prob_{lab}\"] = probs_t3_train[:, j]\n",
    "    cache_cols_train_t3[f\"label_{lab}\"] = labels_t3_train.numpy()[:, j]\n",
    "\n",
    "t3_train_cache = pd.DataFrame(cache_cols_train_t3)\n",
    "t3_train_cache_path = CACHE_DIR / f\"t3_train_probs.csv\"\n",
    "t3_train_cache.to_csv(t3_train_cache_path, index=False)\n",
    "print(\"Saved T3 TRAIN probs to cache:\", t3_train_cache_path)\n",
    "\n",
    "# 4.8 Inference on DEV (unlabeled) + cache DEV probs\n",
    "logits_t3_dev, _ = collect_logits(\n",
    "    trainer_t3,\n",
    "    ds_t3_dev_infer,\n",
    "    is_multilabel=True,\n",
    ")\n",
    "probs_t3_dev = torch.sigmoid(logits_t3_dev / T_t3).cpu().numpy()\n",
    "\n",
    "P3_dev = np.zeros_like(probs_t3_dev, dtype=int)\n",
    "for j, lab in enumerate(T3_LABELS):\n",
    "    thr = float(thr_map_t3[lab])\n",
    "    P3_dev[:, j] = (probs_t3_dev[:, j] >= thr).astype(int)\n",
    "\n",
    "cache_cols_dev_t3 = {\"id\": t3_dev_df[\"id\"].astype(str).values}\n",
    "for j, lab in enumerate(T3_LABELS):\n",
    "    cache_cols_dev_t3[f\"prob_{lab}\"] = probs_t3_dev[:, j]\n",
    "t3_dev_cache = pd.DataFrame(cache_cols_dev_t3)\n",
    "t3_dev_cache_path = CACHE_DIR / f\"t3_dev_probs.csv\"\n",
    "t3_dev_cache.to_csv(t3_dev_cache_path, index=False)\n",
    "print(\"Saved T3 DEV probs to cache:\", t3_dev_cache_path)\n",
    "\n",
    "# 4.9 Save model + calibration\n",
    "trainer_t3.save_model(ART_DIR / f\"native_t3\")\n",
    "with open(ART_DIR / f\"calib_t3_native.json\",\"w\") as f:\n",
    "    json.dump(\n",
    "        {\"temperature\": float(T_t3), \"thresholds\": thr_map_t3},\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "# 4.10 Write Codabench submission CSV for Subtask 3\n",
    "# Required header:\n",
    "#   id,stereotype,vilification,dehumanization,\n",
    "#   extreme_language,lack_of_empathy,invalidation\n",
    "\n",
    "idx_vil      = T3_LABELS.index(\"vilification\")\n",
    "idx_extreme  = T3_LABELS.index(\"extreme_language\")\n",
    "idx_stereo   = T3_LABELS.index(\"stereotype\")\n",
    "idx_invalid  = T3_LABELS.index(\"invalidation\")\n",
    "idx_lackemp  = T3_LABELS.index(\"lack_of_empathy\")\n",
    "idx_dehum    = T3_LABELS.index(\"dehumanization\")\n",
    "\n",
    "sub3 = pd.DataFrame({\n",
    "    \"id\":               t3_dev_df[\"id\"].astype(str).values,\n",
    "    \"stereotype\":       P3_dev[:, idx_stereo],\n",
    "    \"vilification\":     P3_dev[:, idx_vil],\n",
    "    \"dehumanization\":   P3_dev[:, idx_dehum],\n",
    "    \"extreme_language\": P3_dev[:, idx_extreme],\n",
    "    \"lack_of_empathy\":  P3_dev[:, idx_lackemp],\n",
    "    \"invalidation\":     P3_dev[:, idx_invalid],\n",
    "})\n",
    "sub3_path = SUB3_DIR / f\"pred_{LANG}.csv\"\n",
    "sub3.to_csv(sub3_path, index=False)\n",
    "print(\"Saved Codabench file (Subtask 3, XLM-R):\", sub3_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
